{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import math, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianFilter:     #붕어빵기계(클래스)\n",
    "    def __init__(self):   #self:자신(만들어질 객체,붕어빵)\n",
    "        self.words=set()  #붕어빵.길이=15센티, 단어 저장\n",
    "        self.word_dict={} #카테고리(광고/중요) 단어 빈도수\n",
    "        self.category_dict={}  \n",
    "        \n",
    "    def split(self, text):#어미/조사/구두점 제외,형태소분석\n",
    "        result=[]\n",
    "        okt=Okt()\n",
    "        malist=okt.pos(text, norm=True, stem=True)\n",
    "        for word in malist: \n",
    "            if not word[1] in [\"Josa\", \"Eomi\", \"Punctuation\"]:\n",
    "                result.append(word[0])\n",
    "        return result\n",
    "            #print(word[1])        \n",
    "            #조사,어미,구두점을 제외한 나머지 단어만 \n",
    "            #result에 저장\n",
    "    def inc_word(self, word, category):#오늘, 광고\n",
    "        #단어를 카테고리에 추가\n",
    "        if not category in self.word_dict:\n",
    "            self.word_dict[category]={} \n",
    "        if not word in self.word_dict[category]:\n",
    "            self.word_dict[category][word]=0\n",
    "        self.word_dict[category][word]+=1#{'광고':{'파격':1,'오늘':1} , '중요':{ }}\n",
    "        self.words.add(word) #{'파격','오늘'}  \n",
    "    \n",
    "    def inc_category(self, category):\n",
    "        if not category in self.category_dict:\n",
    "            self.category_dict[category]=0\n",
    "        self.category_dict[category]+=1       \n",
    "        \n",
    "    def fit(self,text,category):\n",
    "        word_list=self.split(text)     \n",
    "        for word in word_list:\n",
    "            self.inc_word(word, category)\n",
    "        self.inc_category(category)\n",
    "        #print(word_list)\n",
    "        \n",
    "# 단어 리스트에 점수 매기기\n",
    "    def score(self, words, category):\n",
    "        score = math.log(self.category_prob(category))\n",
    "        for word in words:\n",
    "            score += math.log(self.word_prob(word, category))\n",
    "        return score\n",
    "    \n",
    "    # 예측하기 --- \n",
    "    def predict(self, text):#\"재고 정리 할인,  배송\"\n",
    "        best_category = None\n",
    "        max_score = -sys.maxsize \n",
    "        words = self.split(text)\n",
    "        print(\"words of preFunc:\",words)\n",
    "        score_list = []\n",
    "        for category in self.category_dict.keys():\n",
    "            print(\"category:\",category)\n",
    "            score = self.score(words, category)\n",
    "            score_list.append((category, score))\n",
    "            if score > max_score:\n",
    "                max_score = score\n",
    "                best_category = category\n",
    "        return best_category, score_list\n",
    "    \n",
    "    # 카테고리 내부의 단어 출현 횟수 구하기\n",
    "    def get_word_count(self, word, category):\n",
    "        if word in self.word_dict[category]:\n",
    "            return self.word_dict[category][word]\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    # 카테고리 계산\n",
    "    def category_prob(self, category):\n",
    "        print(\"점수:\",self.category_dict.values())\n",
    "        sum_categories = sum(self.category_dict.values())\n",
    "        #print(category, \"점수:\", sum_categories)\n",
    "        category_v = self.category_dict[category]\n",
    "        return category_v / sum_categories\n",
    "        \n",
    "    # 카테고리 내부의 단어 출현 비율 계산 \n",
    "    def word_prob(self, word, category):\n",
    "        n = self.get_word_count(word, category) + 1 \n",
    "        d = sum(self.word_dict[category].values()) + len(self.words)\n",
    "        return n / d    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words of preFunc: ['재고', '정리', '할인', '배송']\n",
      "category: 광고\n",
      "점수: dict_values([8, 7])\n",
      "category: 중요\n",
      "점수: dict_values([8, 7])\n",
      "결과: 광고\n",
      "[('광고', -16.058261071143168), ('중요', -17.33467895761303)]\n",
      "words of preFunc: ['오늘', '멀티', '캠', '회의', '어떻다']\n",
      "category: 광고\n",
      "점수: dict_values([8, 7])\n",
      "category: 중요\n",
      "점수: dict_values([8, 7])\n",
      "결과: 중요\n",
      "[('광고', -21.563592607075527), ('중요', -18.99290703421656)]\n"
     ]
    }
   ],
   "source": [
    "bf=BayesianFilter()   #붕어빵기계에서 붕어빵 1개 만들어라\n",
    "bf.fit(\"파격 세일 - 오늘까지만 50% 할인\", \"광고\")\n",
    "bf.fit(\"무료 쿠폰 선물 & 무료 배송\", \"광고\")\n",
    "bf.fit(\"아사히 맥주 세일\", \"광고\")\n",
    "bf.fit(\"회의 일정 확인 부탁드립니다\", \"중요\")\n",
    "bf.fit(\"오늘 일정이 없습니다\", \"중요\")\n",
    "bf.fit(\"파격 세일 - 오늘까지만 50% 할인\", \"광고\")\n",
    "bf.fit(\"쿠폰 선물 & 무료 배송\", \"광고\")\n",
    "bf.fit(\"현데계 백화점 세일\", \"광고\")\n",
    "bf.fit(\"봄과 함께 찾아온 따뜻한 신제품 소식\", \"광고\")\n",
    "bf.fit(\"인기 제품 기간 한정 세일\", \"광고\")\n",
    "bf.fit(\"오늘 일정 확인\", \"중요\")\n",
    "bf.fit(\"프로젝트 진행 상황 보고\",\"중요\")\n",
    "bf.fit(\"계약 잘 부탁드립니다\",\"중요\")\n",
    "bf.fit(\"회의 일정이 등록되었습니다.\",\"중요\")\n",
    "bf.fit(\"오늘 일정이 없습니다.\",\"중요\")\n",
    "res, scorelist=bf.predict(\"재고 정리 할인,  배송\")\n",
    "print(\"결과:\", res) #중요 or 광고\n",
    "print(scorelist)#중요메일/광고메일 베이지안 필터기 각 확률\n",
    "\n",
    "# B=중요, A=재고,정리,할인,배송\n",
    "# P(B|A)=P(B)*P(A|B), P(A|B)=P(Aa1|B)P(Aa2|B)...P(Aan|B)\n",
    "# P(중요|재고,정리,할인,배송)=P(중요)*P(재고,정리,할인,배송|중요)\n",
    "\n",
    "res, scorelist=bf.predict(\"오늘 멀티캠에서 회의는 어땠습니까?\")\n",
    "print(\"결과:\", res) #중요 or 광고\n",
    "print(scorelist)#중요메일/광고메일 베이지안 필터기 각 확률\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "class BayesianFilter:\n",
    "  \n",
    "  def __init__(self):\n",
    "    self.words = set() # 단어 저장\n",
    "    self.word_dict = {} # 카테고리 단어 빈도수\n",
    "    self.category_dict = {} # 카테고리(광고 / 중요) 단어 빈도수\n",
    "  def split(self, text): # 어미/조사/구두점 제외, 형태소 분석\n",
    "    result = []\n",
    "    okt = Okt()\n",
    "    malist = okt.pos(text, norm=True, stem=True)\n",
    "    for word in malist:\n",
    "      exceptlist = [\"Josa\", \"Eomi\", \"Punctuation\"]\n",
    "      # 조사, 어미, 구두점 제외한 나머지 단어만 result에 저장\n",
    "      if word[1] not in exceptlist:\n",
    "        result.append(word[0])\n",
    "    return result\n",
    "  def inc_word(self, word, category):\n",
    "    # 단어를 카테고리에 추가\n",
    "    if not category in self.word_dict:\n",
    "      self.word_dict[category] = {} # {'광고':{}}\n",
    "    if not word in self.word_dict[category]:\n",
    "      self.word_dict[category][word] = 0 # {'광고':{'파격':0}}\n",
    "    self.word_dict[category][word] += 1 # {'광고':{'파격':1}}\n",
    "    self.words.add(word) # \n",
    "\n",
    "  def inc_category(self, category):\n",
    "    if not category in self.category_dict:\n",
    "      self.category_dict[category] = 0\n",
    "    self.category_dict[category] += 1\n",
    "    \n",
    "  # 예측\n",
    "  def predict(self, text):\n",
    "    pred_word_list = self.split(text)\n",
    "    ansdict = {}\n",
    "    tot_num = 0\n",
    "    for category in self.category_dict.keys():\n",
    "      tot_num += self.category_dict[category]\n",
    "    for category in self.category_dict.keys():\n",
    "      score_by_cat = 1\n",
    "      for word in pred_word_list:\n",
    "        if word not in self.word_dict[category]:\n",
    "          freq = 1\n",
    "        else :\n",
    "          freq = self.word_dict[category][word]\n",
    "        score_by_cat *= (freq / self.category_dict[category])\n",
    "      ansdict[category] = score_by_cat * (self.category_dict[category]/tot_num)\n",
    "    anslist = list(ansdict.items()) # enum list처럼 쓸 수 있음\n",
    "    anslist.sort(key=lambda x:x[1], reverse=True)\n",
    "    res = anslist[0][0]\n",
    "    scorelist = anslist\n",
    "    \n",
    "    return res, scorelist\n",
    "    \n",
    "  def fit(self, text, category):\n",
    "    word_list = self.split(text)\n",
    "    for word in word_list:\n",
    "      self.inc_word(word, category)\n",
    "    self.inc_category(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words of preFunc: ['재고', '정리', '할인', '배송']\n",
      "category: 광고\n",
      "점수: dict_values([8, 7])\n",
      "category: 중요\n",
      "점수: dict_values([8, 7])\n",
      "결과: 광고\n",
      "[('광고', -16.058261071143168), ('중요', -17.33467895761303)]\n"
     ]
    }
   ],
   "source": [
    "res, scorelist=bf.predict(\"재고 정리 할인,  배송\")\n",
    "print(\"결과:\", res) #중요 or 광고\n",
    "print(scorelist)#중요메일/광고메일 베이지안 필터기 각 확률\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras 선형회귀, 로지스틱 회귀, 소프트맥스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 16:03:33.358686  9176 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0812 16:03:33.369810  9176 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 583.1417 - mean_squared_error: 583.1417\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 937us/step - loss: 94.0964 - mean_squared_error: 94.0964\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 978us/step - loss: 93.6131 - mean_squared_error: 93.6131\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 93.2059 - mean_squared_error: 93.2059\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 92.8686 - mean_squared_error: 92.8686\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 92.5952 - mean_squared_error: 92.5952\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 92.3802 - mean_squared_error: 92.3802\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 92.2183 - mean_squared_error: 92.2183\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 770us/step - loss: 92.1051 - mean_squared_error: 92.1051\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 92.0358 - mean_squared_error: 92.0358\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 92.0065 - mean_squared_error: 92.0065\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 583us/step - loss: 92.0136 - mean_squared_error: 92.0136\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 761us/step - loss: 92.0535 - mean_squared_error: 92.0535\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 945us/step - loss: 92.1228 - mean_squared_error: 92.1228\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 92.2189 - mean_squared_error: 92.2189\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 807us/step - loss: 92.3387 - mean_squared_error: 92.3387\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 92.4799 - mean_squared_error: 92.4799\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 92.6400 - mean_squared_error: 92.6400\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 780us/step - loss: 92.8169 - mean_squared_error: 92.8169\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 774us/step - loss: 93.0086 - mean_squared_error: 93.0086\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 93.2134 - mean_squared_error: 93.2134\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 718us/step - loss: 93.4294 - mean_squared_error: 93.4294\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 93.6553 - mean_squared_error: 93.6553\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 93.8895 - mean_squared_error: 93.8895\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 94.1308 - mean_squared_error: 94.1308\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 94.3780 - mean_squared_error: 94.3780\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 94.6299 - mean_squared_error: 94.6299\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 94.8856 - mean_squared_error: 94.8856\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 606us/step - loss: 95.1442 - mean_squared_error: 95.1442\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 733us/step - loss: 95.4048 - mean_squared_error: 95.4048\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 95.6668 - mean_squared_error: 95.6668\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 918us/step - loss: 95.9294 - mean_squared_error: 95.9294\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 96.1920 - mean_squared_error: 96.1920\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 96.4540 - mean_squared_error: 96.4540\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 971us/step - loss: 96.7149 - mean_squared_error: 96.7149\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 96.9744 - mean_squared_error: 96.9744\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 97.2319 - mean_squared_error: 97.2319\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 97.4871 - mean_squared_error: 97.4871\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 792us/step - loss: 97.7396 - mean_squared_error: 97.7396\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 97.9893 - mean_squared_error: 97.9893\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 98.2358 - mean_squared_error: 98.2358\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 98.4789 - mean_squared_error: 98.4789\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 874us/step - loss: 98.7184 - mean_squared_error: 98.7184\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 98.9542 - mean_squared_error: 98.9542\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 99.1861 - mean_squared_error: 99.1861\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 99.4140 - mean_squared_error: 99.4140\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 99.6378 - mean_squared_error: 99.6378\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 99.8573 - mean_squared_error: 99.8573\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 100.0726 - mean_squared_error: 100.0726\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 100.2834 - mean_squared_error: 100.2834\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 100.4900 - mean_squared_error: 100.4900\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 100.6922 - mean_squared_error: 100.6922\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 100.8901 - mean_squared_error: 100.8901\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 101.0835 - mean_squared_error: 101.0835\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 101.2725 - mean_squared_error: 101.2725\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 101.4572 - mean_squared_error: 101.4572\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 681us/step - loss: 101.6375 - mean_squared_error: 101.6375\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 101.8135 - mean_squared_error: 101.8135\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 101.9851 - mean_squared_error: 101.9851\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 102.1526 - mean_squared_error: 102.1526\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 102.3159 - mean_squared_error: 102.3159\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 102.4750 - mean_squared_error: 102.4750\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 102.6301 - mean_squared_error: 102.6301\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 102.7811 - mean_squared_error: 102.7811\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 102.9282 - mean_squared_error: 102.9282\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 103.0714 - mean_squared_error: 103.0714\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 797us/step - loss: 103.2107 - mean_squared_error: 103.2107\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 103.3462 - mean_squared_error: 103.3462\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 103.4782 - mean_squared_error: 103.4782\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 103.6064 - mean_squared_error: 103.6064\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 103.7311 - mean_squared_error: 103.7311\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 103.8524 - mean_squared_error: 103.8524\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 103.9703 - mean_squared_error: 103.9703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 104.0847 - mean_squared_error: 104.0847\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 104.1960 - mean_squared_error: 104.1960\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 104.3041 - mean_squared_error: 104.3041\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 104.4091 - mean_squared_error: 104.4091\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 653us/step - loss: 104.5111 - mean_squared_error: 104.5111\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 621us/step - loss: 104.6100 - mean_squared_error: 104.6100\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 104.7061 - mean_squared_error: 104.7061\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 104.7994 - mean_squared_error: 104.7994\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 104.8899 - mean_squared_error: 104.8899\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 918us/step - loss: 104.9778 - mean_squared_error: 104.9778\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 830us/step - loss: 105.0631 - mean_squared_error: 105.0631\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 105.1458 - mean_squared_error: 105.1458\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 105.2259 - mean_squared_error: 105.2259\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 105.3038 - mean_squared_error: 105.3038\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 105.3792 - mean_squared_error: 105.3792\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 842us/step - loss: 105.4525 - mean_squared_error: 105.4525\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 105.5234 - mean_squared_error: 105.5234\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 88.0495 - mean_squared_error: 88.04 - 0s 889us/step - loss: 105.5922 - mean_squared_error: 105.5922\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 785us/step - loss: 105.6589 - mean_squared_error: 105.6589\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 105.7236 - mean_squared_error: 105.7236\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 701us/step - loss: 105.7863 - mean_squared_error: 105.7863\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 405us/step - loss: 105.8470 - mean_squared_error: 105.8470\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 732us/step - loss: 105.9059 - mean_squared_error: 105.9059\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 911us/step - loss: 105.9629 - mean_squared_error: 105.9629\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 809us/step - loss: 106.0182 - mean_squared_error: 106.0182\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 106.0718 - mean_squared_error: 106.0718\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 751us/step - loss: 106.1237 - mean_squared_error: 106.1237\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 844us/step - loss: 106.1740 - mean_squared_error: 106.1740\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 585us/step - loss: 106.2227 - mean_squared_error: 106.2227\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 831us/step - loss: 106.2699 - mean_squared_error: 106.2699\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 589us/step - loss: 106.3156 - mean_squared_error: 106.3156\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 106.3599 - mean_squared_error: 106.3599\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 106.4028 - mean_squared_error: 106.4028\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 761us/step - loss: 106.4443 - mean_squared_error: 106.4443\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 982us/step - loss: 106.4845 - mean_squared_error: 106.4845\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 910us/step - loss: 106.5234 - mean_squared_error: 106.5234\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 106.5611 - mean_squared_error: 106.5611\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 552us/step - loss: 106.5976 - mean_squared_error: 106.5976\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 106.6330 - mean_squared_error: 106.6330\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 683us/step - loss: 106.6673 - mean_squared_error: 106.6673\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 106.7004 - mean_squared_error: 106.7004\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 720us/step - loss: 106.7325 - mean_squared_error: 106.7325\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 832us/step - loss: 106.7635 - mean_squared_error: 106.7635\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 967us/step - loss: 106.7936 - mean_squared_error: 106.7936\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 915us/step - loss: 106.8227 - mean_squared_error: 106.8227\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 106.8509 - mean_squared_error: 106.8509\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 106.8782 - mean_squared_error: 106.8782\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 106.9046 - mean_squared_error: 106.9046\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 106.9301 - mean_squared_error: 106.9301\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 106.9548 - mean_squared_error: 106.9548\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 106.9788 - mean_squared_error: 106.9788\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.0020 - mean_squared_error: 107.0020\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.0244 - mean_squared_error: 107.0244\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.0461 - mean_squared_error: 107.0461\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 107.0671 - mean_squared_error: 107.0671\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.0874 - mean_squared_error: 107.0874\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.1070 - mean_squared_error: 107.1070\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.1261 - mean_squared_error: 107.1261\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.1445 - mean_squared_error: 107.1445\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.1624 - mean_squared_error: 107.1624\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.1795 - mean_squared_error: 107.1795\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.1963 - mean_squared_error: 107.1963\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.2124 - mean_squared_error: 107.2124\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.2280 - mean_squared_error: 107.2280\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.2431 - mean_squared_error: 107.2431\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.2577 - mean_squared_error: 107.2577\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.2719 - mean_squared_error: 107.2719\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.2856 - mean_squared_error: 107.2856\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 107.2989 - mean_squared_error: 107.2989\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.3117 - mean_squared_error: 107.3117\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.3240 - mean_squared_error: 107.3240\n",
      "Epoch 145/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 444us/step - loss: 107.3360 - mean_squared_error: 107.3360\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.3477 - mean_squared_error: 107.3477\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.3589 - mean_squared_error: 107.3589\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.3697 - mean_squared_error: 107.3697\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.3802 - mean_squared_error: 107.3802\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.3904 - mean_squared_error: 107.3904\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.4002 - mean_squared_error: 107.4002\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.4097 - mean_squared_error: 107.4097\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 751us/step - loss: 107.4189 - mean_squared_error: 107.4189\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 831us/step - loss: 107.4278 - mean_squared_error: 107.4278\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 638us/step - loss: 107.4364 - mean_squared_error: 107.4364\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.4448 - mean_squared_error: 107.4448\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 610us/step - loss: 107.4528 - mean_squared_error: 107.4528\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.4606 - mean_squared_error: 107.4606\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.4681 - mean_squared_error: 107.4681\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.4754 - mean_squared_error: 107.4754\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 956us/step - loss: 107.4824 - mean_squared_error: 107.4824\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 898us/step - loss: 107.4893 - mean_squared_error: 107.4893\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.4958 - mean_squared_error: 107.4958\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 685us/step - loss: 107.5022 - mean_squared_error: 107.5022\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 949us/step - loss: 107.5084 - mean_squared_error: 107.5084\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.5144 - mean_squared_error: 107.5144\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 667us/step - loss: 107.5202 - mean_squared_error: 107.5202\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.5257 - mean_squared_error: 107.5257\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.5311 - mean_squared_error: 107.5311\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.5364 - mean_squared_error: 107.5364\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 107.5414 - mean_squared_error: 107.5414\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.5463 - mean_squared_error: 107.5463\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.5510 - mean_squared_error: 107.5510\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.5557 - mean_squared_error: 107.5557\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.5600 - mean_squared_error: 107.5600\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.5643 - mean_squared_error: 107.5643\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.5684 - mean_squared_error: 107.5684\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.5724 - mean_squared_error: 107.5724\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 107.5763 - mean_squared_error: 107.5763\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 107.5800 - mean_squared_error: 107.5800\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 107.5837 - mean_squared_error: 107.5837\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.5872 - mean_squared_error: 107.5872\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 107.5905 - mean_squared_error: 107.5905\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.5939 - mean_squared_error: 107.5939\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.5970 - mean_squared_error: 107.5970\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 98.2635 - mean_squared_error: 98.26 - 0s 444us/step - loss: 107.6001 - mean_squared_error: 107.6001\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6031 - mean_squared_error: 107.6031\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 107.6059 - mean_squared_error: 107.6059\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.6087 - mean_squared_error: 107.6087\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.6113 - mean_squared_error: 107.6113\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.6139 - mean_squared_error: 107.6139\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6164 - mean_squared_error: 107.6164\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 107.6188 - mean_squared_error: 107.6188\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6212 - mean_squared_error: 107.6212\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.6235 - mean_squared_error: 107.6235\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.6256 - mean_squared_error: 107.6256\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 107.6278 - mean_squared_error: 107.6278\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6298 - mean_squared_error: 107.6298\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.6318 - mean_squared_error: 107.6318\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6337 - mean_squared_error: 107.6337\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 107.6356 - mean_squared_error: 107.6356\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 107.6374 - mean_squared_error: 107.6374\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6391 - mean_squared_error: 107.6391\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 107.6408 - mean_squared_error: 107.6408\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6424 - mean_squared_error: 107.6424\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 107.6440 - mean_squared_error: 107.6440\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6455 - mean_squared_error: 107.6455\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6470 - mean_squared_error: 107.6470\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6484 - mean_squared_error: 107.6484\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 687us/step - loss: 107.6497 - mean_squared_error: 107.6497\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6511 - mean_squared_error: 107.6511\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 796us/step - loss: 107.6524 - mean_squared_error: 107.6524\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6536 - mean_squared_error: 107.6536\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 793us/step - loss: 107.6548 - mean_squared_error: 107.6548\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6560 - mean_squared_error: 107.6560\n",
      "Epoch 216/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 889us/step - loss: 107.6571 - mean_squared_error: 107.6571\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.6582 - mean_squared_error: 107.6582\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 912us/step - loss: 107.6592 - mean_squared_error: 107.6592\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6602 - mean_squared_error: 107.6602\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6612 - mean_squared_error: 107.6612\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 930us/step - loss: 107.6622 - mean_squared_error: 107.6622\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 795us/step - loss: 107.6631 - mean_squared_error: 107.6631\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 975us/step - loss: 107.6640 - mean_squared_error: 107.6640\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 843us/step - loss: 107.6649 - mean_squared_error: 107.6649\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6657 - mean_squared_error: 107.6657\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 799us/step - loss: 107.6665 - mean_squared_error: 107.6665\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 512us/step - loss: 107.6673 - mean_squared_error: 107.6673\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 596us/step - loss: 107.6681 - mean_squared_error: 107.6681\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6687 - mean_squared_error: 107.6687\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 98.6142 - mean_squared_error: 98.61 - 0s 620us/step - loss: 107.6694 - mean_squared_error: 107.6694\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 839us/step - loss: 107.6702 - mean_squared_error: 107.6702\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6708 - mean_squared_error: 107.6708\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 867us/step - loss: 107.6715 - mean_squared_error: 107.6715\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6721 - mean_squared_error: 107.6721\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6727 - mean_squared_error: 107.6727\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: 107.6732 - mean_squared_error: 107.6732\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 706us/step - loss: 107.6738 - mean_squared_error: 107.6738\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 601us/step - loss: 107.6744 - mean_squared_error: 107.6744\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6749 - mean_squared_error: 107.6749\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 796us/step - loss: 107.6754 - mean_squared_error: 107.6754\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6758 - mean_squared_error: 107.6758\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 830us/step - loss: 107.6763 - mean_squared_error: 107.6763\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 952us/step - loss: 107.6768 - mean_squared_error: 107.6768\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 623us/step - loss: 107.6772 - mean_squared_error: 107.6772\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6776 - mean_squared_error: 107.6776\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 853us/step - loss: 107.6780 - mean_squared_error: 107.6780\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6784 - mean_squared_error: 107.6784\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6788 - mean_squared_error: 107.6788\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6792 - mean_squared_error: 107.6792\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6795 - mean_squared_error: 107.6795\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 107.6798 - mean_squared_error: 107.6798\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 107.6802 - mean_squared_error: 107.6802\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.6806 - mean_squared_error: 107.6806\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 812us/step - loss: 107.6809 - mean_squared_error: 107.6809\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6812 - mean_squared_error: 107.6812\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6815 - mean_squared_error: 107.6815\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6818 - mean_squared_error: 107.6818\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6820 - mean_squared_error: 107.6820\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 107.6823 - mean_squared_error: 107.6823\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6826 - mean_squared_error: 107.6826\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 107.6828 - mean_squared_error: 107.6828\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6831 - mean_squared_error: 107.6831\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6833 - mean_squared_error: 107.6833\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 967us/step - loss: 107.6835 - mean_squared_error: 107.6835\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6837 - mean_squared_error: 107.6837\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 443us/step - loss: 107.6840 - mean_squared_error: 107.6840\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6841 - mean_squared_error: 107.6841\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6843 - mean_squared_error: 107.6843\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6846 - mean_squared_error: 107.6846\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.6848 - mean_squared_error: 107.6848\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.6849 - mean_squared_error: 107.6849\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.6851 - mean_squared_error: 107.6851\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6853 - mean_squared_error: 107.6853\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.6854 - mean_squared_error: 107.6854\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6855 - mean_squared_error: 107.6855\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6857 - mean_squared_error: 107.6857\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6859 - mean_squared_error: 107.6859\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6860 - mean_squared_error: 107.6860\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6862 - mean_squared_error: 107.6862\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6862 - mean_squared_error: 107.6862\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6865 - mean_squared_error: 107.6865\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6865 - mean_squared_error: 107.6865\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6866 - mean_squared_error: 107.6866\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6868 - mean_squared_error: 107.6868\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6869 - mean_squared_error: 107.6869\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6870 - mean_squared_error: 107.6870\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 444us/step - loss: 107.6870 - mean_squared_error: 107.6870\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.6872 - mean_squared_error: 107.6872\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 446us/step - loss: 107.6873 - mean_squared_error: 107.6873\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.6874 - mean_squared_error: 107.6874\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 107.6875 - mean_squared_error: 107.6875\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 107.6875 - mean_squared_error: 107.6875\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 107.6876 - mean_squared_error: 107.6876\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 107.6878 - mean_squared_error: 107.6878\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 651us/step - loss: 107.6878 - mean_squared_error: 107.6878\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 835us/step - loss: 107.6879 - mean_squared_error: 107.6879\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 978us/step - loss: 107.6879 - mean_squared_error: 107.6879\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6880 - mean_squared_error: 107.6880\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6881 - mean_squared_error: 107.6881\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6881 - mean_squared_error: 107.6881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d525455b70>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=np.array([1,2,3,4,5,6,7,8,9])#공부시간\n",
    "y=np.array([12,23,34,45,56,77,88,100,90])#점수\n",
    "#7.5시간 공부? 점수?\n",
    "model=Sequential()\n",
    "model.add(Dense(1, input_dim=1, activation='linear'))\n",
    "sgd=optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
    "model.fit(x,y,batch_size=1, epochs=300, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d526454d30>,\n",
       " <matplotlib.lines.Line2D at 0x1d526454f28>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x, model.predict(x), 'b',x,y,'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66.25939]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([7.5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 16:23:53.361973  9176 deprecation.py:323] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 3.9840 - binary_accuracy: 0.5556\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 3.0163 - binary_accuracy: 0.5556\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 2.0973 - binary_accuracy: 0.5556\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 1.3132 - binary_accuracy: 0.5556\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.8487 - binary_accuracy: 0.5556\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.7126 - binary_accuracy: 0.4444\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6902 - binary_accuracy: 0.3333\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6871 - binary_accuracy: 0.4444\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6858 - binary_accuracy: 0.4444\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 842us/step - loss: 0.6840 - binary_accuracy: 0.4444\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6815 - binary_accuracy: 0.4444\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6786 - binary_accuracy: 0.4444\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 930us/step - loss: 0.6756 - binary_accuracy: 0.4444\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 843us/step - loss: 0.6724 - binary_accuracy: 0.4444\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6692 - binary_accuracy: 0.4444\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.6661 - binary_accuracy: 0.4444\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 773us/step - loss: 0.6629 - binary_accuracy: 0.4444\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.6597 - binary_accuracy: 0.4444\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6566 - binary_accuracy: 0.4444\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6535 - binary_accuracy: 0.4444\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6504 - binary_accuracy: 0.4444\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6473 - binary_accuracy: 0.4444\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6443 - binary_accuracy: 0.4444\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6413 - binary_accuracy: 0.4444\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.7063 - binary_accuracy: 0.0000e+0 - 0s 444us/step - loss: 0.6383 - binary_accuracy: 0.4444\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6354 - binary_accuracy: 0.4444\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6324 - binary_accuracy: 0.5556\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6295 - binary_accuracy: 0.5556\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6267 - binary_accuracy: 0.5556\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.6238 - binary_accuracy: 0.5556\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6210 - binary_accuracy: 0.5556\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6182 - binary_accuracy: 0.5556\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6154 - binary_accuracy: 0.5556\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.6127 - binary_accuracy: 0.5556\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6100 - binary_accuracy: 0.5556\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6073 - binary_accuracy: 0.5556\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6046 - binary_accuracy: 0.5556\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.6019 - binary_accuracy: 0.5556\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5993 - binary_accuracy: 0.5556\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5967 - binary_accuracy: 0.5556\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5941 - binary_accuracy: 0.5556\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5915 - binary_accuracy: 0.5556\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5890 - binary_accuracy: 0.5556\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5865 - binary_accuracy: 0.6667\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5840 - binary_accuracy: 0.6667\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5815 - binary_accuracy: 0.6667\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5791 - binary_accuracy: 0.6667\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.5766 - binary_accuracy: 0.6667\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5742 - binary_accuracy: 0.6667\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5719 - binary_accuracy: 0.6667\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5695 - binary_accuracy: 0.6667\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.5671 - binary_accuracy: 0.6667\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5648 - binary_accuracy: 0.6667\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5625 - binary_accuracy: 0.6667\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5602 - binary_accuracy: 0.6667\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5580 - binary_accuracy: 0.6667\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 0.5557 - binary_accuracy: 0.6667\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 0.5535 - binary_accuracy: 0.6667\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5513 - binary_accuracy: 0.6667\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5491 - binary_accuracy: 0.6667\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5469 - binary_accuracy: 0.6667\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5448 - binary_accuracy: 0.6667\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5427 - binary_accuracy: 0.6667\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5405 - binary_accuracy: 0.6667\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.5384 - binary_accuracy: 0.6667\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5364 - binary_accuracy: 0.6667\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 0.5343 - binary_accuracy: 0.6667\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5323 - binary_accuracy: 0.6667\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5302 - binary_accuracy: 0.7778\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5282 - binary_accuracy: 0.7778\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 0.5262 - binary_accuracy: 0.7778\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5243 - binary_accuracy: 0.7778\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5223 - binary_accuracy: 0.7778\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5204 - binary_accuracy: 0.7778\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5185 - binary_accuracy: 0.7778\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5165 - binary_accuracy: 0.7778\n",
      "Epoch 77/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 889us/step - loss: 0.5147 - binary_accuracy: 0.7778\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5128 - binary_accuracy: 0.7778\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.5109 - binary_accuracy: 0.7778\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5091 - binary_accuracy: 0.7778\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5072 - binary_accuracy: 0.7778\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5054 - binary_accuracy: 0.7778\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5036 - binary_accuracy: 0.7778\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5018 - binary_accuracy: 0.7778\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.5001 - binary_accuracy: 0.7778\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4983 - binary_accuracy: 0.7778\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4966 - binary_accuracy: 0.7778\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4948 - binary_accuracy: 0.7778\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4931 - binary_accuracy: 0.7778\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4914 - binary_accuracy: 0.7778\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4897 - binary_accuracy: 0.7778\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4881 - binary_accuracy: 0.7778\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.4864 - binary_accuracy: 0.7778\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.4848 - binary_accuracy: 0.7778\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4831 - binary_accuracy: 0.7778\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4815 - binary_accuracy: 0.7778\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4799 - binary_accuracy: 0.7778\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4783 - binary_accuracy: 0.7778\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4767 - binary_accuracy: 0.7778\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4752 - binary_accuracy: 0.7778\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4736 - binary_accuracy: 0.7778\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4721 - binary_accuracy: 0.7778\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4705 - binary_accuracy: 0.7778\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4690 - binary_accuracy: 0.7778\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.4675 - binary_accuracy: 0.7778\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4660 - binary_accuracy: 0.7778\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4645 - binary_accuracy: 0.7778\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4631 - binary_accuracy: 0.7778\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4616 - binary_accuracy: 0.7778\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4602 - binary_accuracy: 0.7778\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4587 - binary_accuracy: 0.7778\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4573 - binary_accuracy: 0.7778\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.4559 - binary_accuracy: 0.7778\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.4545 - binary_accuracy: 0.7778\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4531 - binary_accuracy: 0.7778\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4517 - binary_accuracy: 0.7778\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4503 - binary_accuracy: 0.7778\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4489 - binary_accuracy: 0.7778\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4476 - binary_accuracy: 0.7778\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4462 - binary_accuracy: 0.7778\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4449 - binary_accuracy: 0.7778\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4436 - binary_accuracy: 0.8889\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4423 - binary_accuracy: 0.8889\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4410 - binary_accuracy: 0.8889\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4397 - binary_accuracy: 0.8889\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4384 - binary_accuracy: 0.8889\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4371 - binary_accuracy: 0.8889\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4359 - binary_accuracy: 0.8889\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4346 - binary_accuracy: 0.8889\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.4334 - binary_accuracy: 0.8889\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.4321 - binary_accuracy: 0.8889\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4309 - binary_accuracy: 0.8889\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4297 - binary_accuracy: 0.8889\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4285 - binary_accuracy: 0.8889\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4273 - binary_accuracy: 0.8889\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4261 - binary_accuracy: 0.8889\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4249 - binary_accuracy: 0.8889\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 443us/step - loss: 0.4237 - binary_accuracy: 0.8889\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4225 - binary_accuracy: 0.8889\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4214 - binary_accuracy: 0.8889\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4202 - binary_accuracy: 0.8889\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4191 - binary_accuracy: 0.8889\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4179 - binary_accuracy: 0.8889\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4168 - binary_accuracy: 0.8889\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4157 - binary_accuracy: 0.8889\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4146 - binary_accuracy: 0.8889\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4135 - binary_accuracy: 0.8889\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4124 - binary_accuracy: 0.8889\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.4113 - binary_accuracy: 0.8889\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 0.4102 - binary_accuracy: 0.8889\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4091 - binary_accuracy: 0.8889\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4081 - binary_accuracy: 0.8889\n",
      "Epoch 153/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 890us/step - loss: 0.4070 - binary_accuracy: 0.8889\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 0.4060 - binary_accuracy: 0.8889\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4049 - binary_accuracy: 0.8889\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.4039 - binary_accuracy: 0.8889\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4029 - binary_accuracy: 0.8889\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.4018 - binary_accuracy: 0.8889\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.4008 - binary_accuracy: 0.8889\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3998 - binary_accuracy: 0.8889\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3988 - binary_accuracy: 0.8889\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3978 - binary_accuracy: 0.8889\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3968 - binary_accuracy: 0.8889\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3958 - binary_accuracy: 0.8889\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3949 - binary_accuracy: 0.8889\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3939 - binary_accuracy: 0.8889\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 0.3929 - binary_accuracy: 0.8889\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.3920 - binary_accuracy: 0.8889\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3910 - binary_accuracy: 0.8889\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.3901 - binary_accuracy: 0.8889\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3891 - binary_accuracy: 0.8889\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3882 - binary_accuracy: 0.8889\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3873 - binary_accuracy: 0.8889\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3864 - binary_accuracy: 0.8889\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3854 - binary_accuracy: 0.8889\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3845 - binary_accuracy: 0.8889\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3836 - binary_accuracy: 0.8889\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.3827 - binary_accuracy: 0.8889\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3818 - binary_accuracy: 0.8889\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3810 - binary_accuracy: 0.8889\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3801 - binary_accuracy: 0.8889\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3792 - binary_accuracy: 0.8889\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3783 - binary_accuracy: 0.8889\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3775 - binary_accuracy: 0.8889\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.3766 - binary_accuracy: 0.8889\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3758 - binary_accuracy: 0.8889\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 0.3749 - binary_accuracy: 0.8889\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3741 - binary_accuracy: 0.8889\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3732 - binary_accuracy: 0.8889\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3724 - binary_accuracy: 0.8889\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.3716 - binary_accuracy: 0.8889\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3708 - binary_accuracy: 0.8889\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3699 - binary_accuracy: 0.8889\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3691 - binary_accuracy: 0.8889\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3683 - binary_accuracy: 0.8889\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3675 - binary_accuracy: 0.8889\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3667 - binary_accuracy: 0.8889\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3659 - binary_accuracy: 0.8889\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 0.3651 - binary_accuracy: 0.8889\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3644 - binary_accuracy: 0.8889\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 0.3636 - binary_accuracy: 0.8889\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1731 - binary_accuracy: 1.000 - 0s 889us/step - loss: 0.3628 - binary_accuracy: 0.8889\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3620 - binary_accuracy: 0.8889\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3613 - binary_accuracy: 0.8889\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3605 - binary_accuracy: 0.8889\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3598 - binary_accuracy: 0.8889\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3590 - binary_accuracy: 0.8889\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3583 - binary_accuracy: 0.8889\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3575 - binary_accuracy: 0.8889\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3568 - binary_accuracy: 0.8889\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3560 - binary_accuracy: 0.8889\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3553 - binary_accuracy: 0.8889\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3546 - binary_accuracy: 0.8889\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3539 - binary_accuracy: 0.8889\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3531 - binary_accuracy: 0.8889\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3524 - binary_accuracy: 0.8889\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3517 - binary_accuracy: 0.8889\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3510 - binary_accuracy: 0.8889\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.3503 - binary_accuracy: 0.8889\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3496 - binary_accuracy: 0.8889\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3489 - binary_accuracy: 0.8889\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3482 - binary_accuracy: 0.8889\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3476 - binary_accuracy: 0.8889\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3469 - binary_accuracy: 0.8889\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3462 - binary_accuracy: 0.8889\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3455 - binary_accuracy: 0.8889\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3449 - binary_accuracy: 0.8889\n",
      "Epoch 228/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 889us/step - loss: 0.3442 - binary_accuracy: 0.8889\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 0.1470 - binary_accuracy: 1.000 - 0s 889us/step - loss: 0.3435 - binary_accuracy: 0.8889\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3429 - binary_accuracy: 0.8889\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3422 - binary_accuracy: 0.8889\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3416 - binary_accuracy: 0.8889\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3409 - binary_accuracy: 0.8889\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3403 - binary_accuracy: 0.8889\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3396 - binary_accuracy: 0.8889\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3390 - binary_accuracy: 0.8889\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3384 - binary_accuracy: 0.8889\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3377 - binary_accuracy: 0.8889\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3371 - binary_accuracy: 0.8889\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3365 - binary_accuracy: 0.8889\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3359 - binary_accuracy: 0.8889\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3352 - binary_accuracy: 0.8889\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3346 - binary_accuracy: 0.8889\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3340 - binary_accuracy: 0.8889\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3334 - binary_accuracy: 0.8889\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3328 - binary_accuracy: 0.8889\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3322 - binary_accuracy: 0.8889\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 0.3316 - binary_accuracy: 0.8889\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.3310 - binary_accuracy: 0.8889\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3304 - binary_accuracy: 0.8889\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3298 - binary_accuracy: 0.8889\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 444us/step - loss: 0.3292 - binary_accuracy: 0.8889\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3287 - binary_accuracy: 0.8889\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3281 - binary_accuracy: 0.8889\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3275 - binary_accuracy: 0.8889\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3269 - binary_accuracy: 0.8889\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3264 - binary_accuracy: 0.8889\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3258 - binary_accuracy: 0.8889\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3252 - binary_accuracy: 0.8889\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3247 - binary_accuracy: 0.8889\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3241 - binary_accuracy: 0.8889\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3235 - binary_accuracy: 0.8889\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3230 - binary_accuracy: 0.8889\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3224 - binary_accuracy: 0.8889\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3219 - binary_accuracy: 0.8889\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3213 - binary_accuracy: 0.8889\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3208 - binary_accuracy: 0.8889\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3203 - binary_accuracy: 0.8889\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3197 - binary_accuracy: 0.8889\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 445us/step - loss: 0.3192 - binary_accuracy: 0.8889\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 0.3187 - binary_accuracy: 0.8889\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3181 - binary_accuracy: 0.8889\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 0.3176 - binary_accuracy: 0.8889\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 0.3171 - binary_accuracy: 0.8889\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3166 - binary_accuracy: 0.8889\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3160 - binary_accuracy: 0.8889\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3155 - binary_accuracy: 0.8889\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3150 - binary_accuracy: 0.8889\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3145 - binary_accuracy: 0.8889\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 0.3140 - binary_accuracy: 0.8889\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3135 - binary_accuracy: 0.8889\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3130 - binary_accuracy: 0.8889\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3125 - binary_accuracy: 0.8889\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 890us/step - loss: 0.3120 - binary_accuracy: 0.8889\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3115 - binary_accuracy: 0.8889\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3110 - binary_accuracy: 0.8889\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3105 - binary_accuracy: 0.8889\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3100 - binary_accuracy: 0.8889\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3095 - binary_accuracy: 0.8889\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3090 - binary_accuracy: 0.8889\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 0.3085 - binary_accuracy: 0.8889\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3081 - binary_accuracy: 0.8889\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3076 - binary_accuracy: 0.8889\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3071 - binary_accuracy: 0.8889\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3066 - binary_accuracy: 0.8889\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3062 - binary_accuracy: 0.8889\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3057 - binary_accuracy: 0.8889\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3052 - binary_accuracy: 0.8889\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3047 - binary_accuracy: 0.8889\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 889us/step - loss: 0.3043 - binary_accuracy: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d52623c518>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#로지스틱 회귀\n",
    "\n",
    "x=np.array([1,2,3,4,5,6,7,8,9])#공부시간\n",
    "y=np.array([0,0,0,0,0,1,1,1,1])#합격여부\n",
    "#7.5시간 공부? \n",
    "model=Sequential()\n",
    "model.add(Dense(1, input_dim=1, activation='sigmoid'))\n",
    "sgd=optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "model.fit(x,y,batch_size=1, epochs=300, shuffle=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d52672af98>,\n",
       " <matplotlib.lines.Line2D at 0x1d526734128>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, model.predict(x), 'b',x,y,'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07137062],\n",
       "       [0.12483826]], dtype=float32)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([15, 17])\n",
    "model.predict([0.5, 1.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 15292.8567 - mean_squared_error: 15292.8567\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 964.8978 - mean_squared_error: 964.8978\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 257.9041 - mean_squared_error: 257.9041\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 265.5106 - mean_squared_error: 265.5106\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 277.9837 - mean_squared_error: 277.9837\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 280.3875 - mean_squared_error: 280.3875\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 279.5440 - mean_squared_error: 279.5440\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 277.8587 - mean_squared_error: 277.8587\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 275.9834 - mean_squared_error: 275.9834\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 274.0849 - mean_squared_error: 274.0849\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 272.2062 - mean_squared_error: 272.2062\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 270.3569 - mean_squared_error: 270.3569\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 268.5387 - mean_squared_error: 268.5387\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 266.7521 - mean_squared_error: 266.7521\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 264.9968 - mean_squared_error: 264.9968\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 263.2724 - mean_squared_error: 263.2724\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 261.5777 - mean_squared_error: 261.5777\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 259.9125 - mean_squared_error: 259.9125\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 258.2764 - mean_squared_error: 258.2764\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 256.6686 - mean_squared_error: 256.6686\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 255.0891 - mean_squared_error: 255.0891\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 253.5371 - mean_squared_error: 253.5371\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 252.0117 - mean_squared_error: 252.0117\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 250.5126 - mean_squared_error: 250.5126\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 249.0393 - mean_squared_error: 249.0393\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 247.5921 - mean_squared_error: 247.5921\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 246.1695 - mean_squared_error: 246.1695\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 244.7716 - mean_squared_error: 244.7716\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 243.3977 - mean_squared_error: 243.3977\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 242.0475 - mean_squared_error: 242.0475\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 240.7205 - mean_squared_error: 240.7205\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 239.4163 - mean_squared_error: 239.4163\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 238.1349 - mean_squared_error: 238.1349\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 236.8749 - mean_squared_error: 236.8749\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 235.6369 - mean_squared_error: 235.6369\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 234.4197 - mean_squared_error: 234.4197\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 233.2237 - mean_squared_error: 233.2237\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 232.0478 - mean_squared_error: 232.0478\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 230.8921 - mean_squared_error: 230.8921\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 229.7562 - mean_squared_error: 229.7562\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 228.6396 - mean_squared_error: 228.6396\n",
      "Epoch 42/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 227.5422 - mean_squared_error: 227.5422\n",
      "Epoch 43/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 226.4630 - mean_squared_error: 226.4630\n",
      "Epoch 44/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 225.4024 - mean_squared_error: 225.4024\n",
      "Epoch 45/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 224.3598 - mean_squared_error: 224.3598\n",
      "Epoch 46/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 223.3348 - mean_squared_error: 223.3348\n",
      "Epoch 47/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 222.3273 - mean_squared_error: 222.3273\n",
      "Epoch 48/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 221.3366 - mean_squared_error: 221.3366\n",
      "Epoch 49/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 220.3626 - mean_squared_error: 220.3626\n",
      "Epoch 50/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 219.4053 - mean_squared_error: 219.4053\n",
      "Epoch 51/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 218.4637 - mean_squared_error: 218.4637\n",
      "Epoch 52/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 217.5385 - mean_squared_error: 217.5385\n",
      "Epoch 53/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 216.6283 - mean_squared_error: 216.6283\n",
      "Epoch 54/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 215.7336 - mean_squared_error: 215.7336\n",
      "Epoch 55/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 214.8540 - mean_squared_error: 214.8540\n",
      "Epoch 56/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 213.9890 - mean_squared_error: 213.9890\n",
      "Epoch 57/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 213.1385 - mean_squared_error: 213.1385\n",
      "Epoch 58/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 212.3023 - mean_squared_error: 212.3023\n",
      "Epoch 59/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 211.4800 - mean_squared_error: 211.4800\n",
      "Epoch 60/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 210.6714 - mean_squared_error: 210.6714\n",
      "Epoch 61/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 209.8762 - mean_squared_error: 209.8762\n",
      "Epoch 62/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 209.0944 - mean_squared_error: 209.0944\n",
      "Epoch 63/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 208.3251 - mean_squared_error: 208.3251\n",
      "Epoch 64/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 207.5690 - mean_squared_error: 207.5690\n",
      "Epoch 65/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 206.8254 - mean_squared_error: 206.8254\n",
      "Epoch 66/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 206.0939 - mean_squared_error: 206.0939\n",
      "Epoch 67/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 205.3745 - mean_squared_error: 205.3745\n",
      "Epoch 68/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 204.6675 - mean_squared_error: 204.6675\n",
      "Epoch 69/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 203.9713 - mean_squared_error: 203.9713\n",
      "Epoch 70/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 203.2870 - mean_squared_error: 203.2870\n",
      "Epoch 71/300\n",
      "3/3 [==============================] - 0s 609us/step - loss: 202.6143 - mean_squared_error: 202.6143\n",
      "Epoch 72/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 201.9520 - mean_squared_error: 201.9520\n",
      "Epoch 73/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 201.3011 - mean_squared_error: 201.3011\n",
      "Epoch 74/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 200.6603 - mean_squared_error: 200.6603\n",
      "Epoch 75/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 200.0305 - mean_squared_error: 200.0305\n",
      "Epoch 76/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 199.4105 - mean_squared_error: 199.4105\n",
      "Epoch 77/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 198.8011 - mean_squared_error: 198.8011\n",
      "Epoch 78/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 198.2015 - mean_squared_error: 198.2015\n",
      "Epoch 79/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 197.6114 - mean_squared_error: 197.6114\n",
      "Epoch 80/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 197.0310 - mean_squared_error: 197.0310\n",
      "Epoch 81/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 196.4601 - mean_squared_error: 196.4601\n",
      "Epoch 82/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 195.8986 - mean_squared_error: 195.8986\n",
      "Epoch 83/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 195.3458 - mean_squared_error: 195.3458\n",
      "Epoch 84/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 194.8022 - mean_squared_error: 194.8022\n",
      "Epoch 85/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 194.2673 - mean_squared_error: 194.2673\n",
      "Epoch 86/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 193.7410 - mean_squared_error: 193.7410\n",
      "Epoch 87/300\n",
      "3/3 [==============================] - 0s 415us/step - loss: 193.2231 - mean_squared_error: 193.2231\n",
      "Epoch 88/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 192.7136 - mean_squared_error: 192.7136\n",
      "Epoch 89/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 192.2124 - mean_squared_error: 192.2124\n",
      "Epoch 90/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 191.7189 - mean_squared_error: 191.7189\n",
      "Epoch 91/300\n",
      "3/3 [==============================] - 0s 595us/step - loss: 191.2336 - mean_squared_error: 191.2336\n",
      "Epoch 92/300\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 190.7561 - mean_squared_error: 190.7561\n",
      "Epoch 93/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 190.2858 - mean_squared_error: 190.2858\n",
      "Epoch 94/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 189.8234 - mean_squared_error: 189.8234\n",
      "Epoch 95/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 189.3682 - mean_squared_error: 189.3682\n",
      "Epoch 96/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 188.9203 - mean_squared_error: 188.9203\n",
      "Epoch 97/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 188.4794 - mean_squared_error: 188.4794\n",
      "Epoch 98/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 188.0457 - mean_squared_error: 188.0457\n",
      "Epoch 99/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 187.6186 - mean_squared_error: 187.6186\n",
      "Epoch 100/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 187.1984 - mean_squared_error: 187.1984\n",
      "Epoch 101/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 186.7846 - mean_squared_error: 186.7846\n",
      "Epoch 102/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 186.3777 - mean_squared_error: 186.3777\n",
      "Epoch 103/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 185.9769 - mean_squared_error: 185.9769\n",
      "Epoch 104/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 185.5824 - mean_squared_error: 185.5824\n",
      "Epoch 105/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 185.1941 - mean_squared_error: 185.1941\n",
      "Epoch 106/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 184.8122 - mean_squared_error: 184.8122\n",
      "Epoch 107/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 184.4360 - mean_squared_error: 184.4360\n",
      "Epoch 108/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 184.0654 - mean_squared_error: 184.0654\n",
      "Epoch 109/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 183.7009 - mean_squared_error: 183.7009\n",
      "Epoch 110/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 183.3421 - mean_squared_error: 183.3421\n",
      "Epoch 111/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 182.9888 - mean_squared_error: 182.9888\n",
      "Epoch 112/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 182.6408 - mean_squared_error: 182.6408\n",
      "Epoch 113/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 182.2983 - mean_squared_error: 182.2983\n",
      "Epoch 114/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 181.9611 - mean_squared_error: 181.9611\n",
      "Epoch 115/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 181.6292 - mean_squared_error: 181.6292\n",
      "Epoch 116/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 181.3022 - mean_squared_error: 181.3022\n",
      "Epoch 117/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 180.9806 - mean_squared_error: 180.9806\n",
      "Epoch 118/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 180.6637 - mean_squared_error: 180.6637\n",
      "Epoch 119/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 180.3516 - mean_squared_error: 180.3516\n",
      "Epoch 120/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 180.0442 - mean_squared_error: 180.0442\n",
      "Epoch 121/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 179.7419 - mean_squared_error: 179.7419\n",
      "Epoch 122/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 179.4439 - mean_squared_error: 179.4439\n",
      "Epoch 123/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 179.1503 - mean_squared_error: 179.1503\n",
      "Epoch 124/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 178.8614 - mean_squared_error: 178.8614\n",
      "Epoch 125/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 178.5770 - mean_squared_error: 178.5770\n",
      "Epoch 126/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 178.2968 - mean_squared_error: 178.2968\n",
      "Epoch 127/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 178.0206 - mean_squared_error: 178.0206\n",
      "Epoch 128/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 177.7488 - mean_squared_error: 177.7488\n",
      "Epoch 129/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 177.4810 - mean_squared_error: 177.4810\n",
      "Epoch 130/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 177.2173 - mean_squared_error: 177.2173\n",
      "Epoch 131/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 176.9576 - mean_squared_error: 176.9576\n",
      "Epoch 132/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 176.7015 - mean_squared_error: 176.7015\n",
      "Epoch 133/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 176.4495 - mean_squared_error: 176.4495\n",
      "Epoch 134/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 176.2013 - mean_squared_error: 176.2013\n",
      "Epoch 135/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 175.9568 - mean_squared_error: 175.9568\n",
      "Epoch 136/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 175.7159 - mean_squared_error: 175.7159\n",
      "Epoch 137/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 175.4786 - mean_squared_error: 175.4786\n",
      "Epoch 138/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 175.2447 - mean_squared_error: 175.2447\n",
      "Epoch 139/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 175.0145 - mean_squared_error: 175.0145\n",
      "Epoch 140/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 174.7876 - mean_squared_error: 174.7876\n",
      "Epoch 141/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 174.5639 - mean_squared_error: 174.5639\n",
      "Epoch 142/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 174.3437 - mean_squared_error: 174.3437\n",
      "Epoch 143/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 174.1269 - mean_squared_error: 174.1269\n",
      "Epoch 144/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 173.9127 - mean_squared_error: 173.9127\n",
      "Epoch 145/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 173.7019 - mean_squared_error: 173.7019\n",
      "Epoch 146/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 173.4944 - mean_squared_error: 173.4944\n",
      "Epoch 147/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 173.2898 - mean_squared_error: 173.2898\n",
      "Epoch 148/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 173.0882 - mean_squared_error: 173.0882\n",
      "Epoch 149/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 172.8896 - mean_squared_error: 172.8896\n",
      "Epoch 150/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 172.6936 - mean_squared_error: 172.6936\n",
      "Epoch 151/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 172.5006 - mean_squared_error: 172.5006\n",
      "Epoch 152/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 172.3107 - mean_squared_error: 172.3107\n",
      "Epoch 153/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 172.1232 - mean_squared_error: 172.1232\n",
      "Epoch 154/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 171.9383 - mean_squared_error: 171.9383\n",
      "Epoch 155/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 171.7565 - mean_squared_error: 171.7565\n",
      "Epoch 156/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 171.5769 - mean_squared_error: 171.5769\n",
      "Epoch 157/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 171.4001 - mean_squared_error: 171.4001\n",
      "Epoch 158/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 171.2258 - mean_squared_error: 171.2258\n",
      "Epoch 159/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 171.0539 - mean_squared_error: 171.0539\n",
      "Epoch 160/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 170.8845 - mean_squared_error: 170.8845\n",
      "Epoch 161/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 170.7175 - mean_squared_error: 170.7175\n",
      "Epoch 162/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 170.5530 - mean_squared_error: 170.5530\n",
      "Epoch 163/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 170.3906 - mean_squared_error: 170.3906\n",
      "Epoch 164/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 170.2309 - mean_squared_error: 170.2309\n",
      "Epoch 165/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 170.0731 - mean_squared_error: 170.0731\n",
      "Epoch 166/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 169.9176 - mean_squared_error: 169.9176\n",
      "Epoch 167/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 169.7644 - mean_squared_error: 169.7644\n",
      "Epoch 168/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 169.6132 - mean_squared_error: 169.6132\n",
      "Epoch 169/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 169.4642 - mean_squared_error: 169.4642\n",
      "Epoch 170/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 169.3172 - mean_squared_error: 169.3172\n",
      "Epoch 171/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 169.1724 - mean_squared_error: 169.1724\n",
      "Epoch 172/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 169.0294 - mean_squared_error: 169.0294\n",
      "Epoch 173/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 168.8886 - mean_squared_error: 168.8886\n",
      "Epoch 174/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 168.7496 - mean_squared_error: 168.7496\n",
      "Epoch 175/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 168.6126 - mean_squared_error: 168.6126\n",
      "Epoch 176/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 168.4775 - mean_squared_error: 168.4775\n",
      "Epoch 177/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 168.3443 - mean_squared_error: 168.3443\n",
      "Epoch 178/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 168.2130 - mean_squared_error: 168.2130\n",
      "Epoch 179/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 168.0834 - mean_squared_error: 168.0834\n",
      "Epoch 180/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 167.9557 - mean_squared_error: 167.9557\n",
      "Epoch 181/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 167.8295 - mean_squared_error: 167.8295\n",
      "Epoch 182/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 167.7052 - mean_squared_error: 167.7052\n",
      "Epoch 183/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 167.5825 - mean_squared_error: 167.5825\n",
      "Epoch 184/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 167.4617 - mean_squared_error: 167.4617\n",
      "Epoch 185/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 167.3423 - mean_squared_error: 167.3423\n",
      "Epoch 186/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 167.2246 - mean_squared_error: 167.2246\n",
      "Epoch 187/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 167.1083 - mean_squared_error: 167.1083\n",
      "Epoch 188/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 166.9939 - mean_squared_error: 166.9939\n",
      "Epoch 189/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 166.8809 - mean_squared_error: 166.8809\n",
      "Epoch 190/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 166.7694 - mean_squared_error: 166.7694\n",
      "Epoch 191/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 166.6595 - mean_squared_error: 166.6595\n",
      "Epoch 192/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 166.5511 - mean_squared_error: 166.5511\n",
      "Epoch 193/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 166.4438 - mean_squared_error: 166.4438\n",
      "Epoch 194/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 166.3382 - mean_squared_error: 166.3382\n",
      "Epoch 195/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 166.2340 - mean_squared_error: 166.2340\n",
      "Epoch 196/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 166.1313 - mean_squared_error: 166.1313\n",
      "Epoch 197/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 166.0297 - mean_squared_error: 166.0297\n",
      "Epoch 198/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 165.9297 - mean_squared_error: 165.9297\n",
      "Epoch 199/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 165.8308 - mean_squared_error: 165.8308\n",
      "Epoch 200/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 165.7332 - mean_squared_error: 165.7332\n",
      "Epoch 201/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 165.6372 - mean_squared_error: 165.6372\n",
      "Epoch 202/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 165.5422 - mean_squared_error: 165.5422\n",
      "Epoch 203/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 165.4484 - mean_squared_error: 165.4484\n",
      "Epoch 204/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 165.3558 - mean_squared_error: 165.3558\n",
      "Epoch 205/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 165.2648 - mean_squared_error: 165.2648\n",
      "Epoch 206/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 165.1744 - mean_squared_error: 165.1744\n",
      "Epoch 207/300\n",
      "3/3 [==============================] - 0s 2ms/step - loss: 165.0858 - mean_squared_error: 165.0858\n",
      "Epoch 208/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 164.9979 - mean_squared_error: 164.9979\n",
      "Epoch 209/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 164.9112 - mean_squared_error: 164.9112\n",
      "Epoch 210/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 164.8258 - mean_squared_error: 164.8258\n",
      "Epoch 211/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 164.7415 - mean_squared_error: 164.7415\n",
      "Epoch 212/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 164.6581 - mean_squared_error: 164.6581\n",
      "Epoch 213/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 164.5759 - mean_squared_error: 164.5759\n",
      "Epoch 214/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 164.4948 - mean_squared_error: 164.4948\n",
      "Epoch 215/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 164.4145 - mean_squared_error: 164.4145\n",
      "Epoch 216/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 164.3354 - mean_squared_error: 164.3354\n",
      "Epoch 217/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 164.2573 - mean_squared_error: 164.2573\n",
      "Epoch 218/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 164.1801 - mean_squared_error: 164.1801\n",
      "Epoch 219/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 164.1040 - mean_squared_error: 164.1040\n",
      "Epoch 220/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 164.0288 - mean_squared_error: 164.0288\n",
      "Epoch 221/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 163.9545 - mean_squared_error: 163.9545\n",
      "Epoch 222/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 163.8811 - mean_squared_error: 163.8811\n",
      "Epoch 223/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 163.8089 - mean_squared_error: 163.8089\n",
      "Epoch 224/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 163.7373 - mean_squared_error: 163.7373\n",
      "Epoch 225/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 163.6668 - mean_squared_error: 163.6668\n",
      "Epoch 226/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 163.5970 - mean_squared_error: 163.5970\n",
      "Epoch 227/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 163.5283 - mean_squared_error: 163.5283\n",
      "Epoch 228/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 163.4603 - mean_squared_error: 163.4603\n",
      "Epoch 229/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 163.3931 - mean_squared_error: 163.3931\n",
      "Epoch 230/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 163.3269 - mean_squared_error: 163.3269\n",
      "Epoch 231/300\n",
      "3/3 [==============================] - 0s 526us/step - loss: 163.2613 - mean_squared_error: 163.2613\n",
      "Epoch 232/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 163.1966 - mean_squared_error: 163.1966\n",
      "Epoch 233/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 163.1327 - mean_squared_error: 163.1327\n",
      "Epoch 234/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 163.0697 - mean_squared_error: 163.0697\n",
      "Epoch 235/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 163.0074 - mean_squared_error: 163.0074\n",
      "Epoch 236/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 162.9458 - mean_squared_error: 162.9458\n",
      "Epoch 237/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 162.8850 - mean_squared_error: 162.8850\n",
      "Epoch 238/300\n",
      "3/3 [==============================] - ETA: 0s - loss: 189.3687 - mean_squared_error: 189.36 - 0s 0us/step - loss: 162.8249 - mean_squared_error: 162.8249\n",
      "Epoch 239/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 162.7655 - mean_squared_error: 162.7655\n",
      "Epoch 240/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 162.7069 - mean_squared_error: 162.7069\n",
      "Epoch 241/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 162.6489 - mean_squared_error: 162.6489\n",
      "Epoch 242/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 162.5917 - mean_squared_error: 162.5917\n",
      "Epoch 243/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 162.5353 - mean_squared_error: 162.5353\n",
      "Epoch 244/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 162.4794 - mean_squared_error: 162.4794\n",
      "Epoch 245/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 162.4242 - mean_squared_error: 162.4242\n",
      "Epoch 246/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 162.3696 - mean_squared_error: 162.3696\n",
      "Epoch 247/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 162.3157 - mean_squared_error: 162.3157\n",
      "Epoch 248/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 162.2625 - mean_squared_error: 162.2625\n",
      "Epoch 249/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 162.2099 - mean_squared_error: 162.2099\n",
      "Epoch 250/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 162.1579 - mean_squared_error: 162.1579\n",
      "Epoch 251/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 162.1066 - mean_squared_error: 162.1066\n",
      "Epoch 252/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 162.0558 - mean_squared_error: 162.0558\n",
      "Epoch 253/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 162.0056 - mean_squared_error: 162.0056\n",
      "Epoch 254/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.9561 - mean_squared_error: 161.9561\n",
      "Epoch 255/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.9072 - mean_squared_error: 161.9072\n",
      "Epoch 256/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 161.8587 - mean_squared_error: 161.8587\n",
      "Epoch 257/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.8109 - mean_squared_error: 161.8109\n",
      "Epoch 258/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.7635 - mean_squared_error: 161.7635\n",
      "Epoch 259/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.7168 - mean_squared_error: 161.7168\n",
      "Epoch 260/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 161.6707 - mean_squared_error: 161.6707\n",
      "Epoch 261/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.6249 - mean_squared_error: 161.6249\n",
      "Epoch 262/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.5798 - mean_squared_error: 161.5798\n",
      "Epoch 263/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.5353 - mean_squared_error: 161.5353\n",
      "Epoch 264/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.4912 - mean_squared_error: 161.4912\n",
      "Epoch 265/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.4474 - mean_squared_error: 161.4474\n",
      "Epoch 266/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.4045 - mean_squared_error: 161.4045\n",
      "Epoch 267/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.3617 - mean_squared_error: 161.3617\n",
      "Epoch 268/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.3197 - mean_squared_error: 161.3197\n",
      "Epoch 269/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.2780 - mean_squared_error: 161.2780\n",
      "Epoch 270/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.2370 - mean_squared_error: 161.2370\n",
      "Epoch 271/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.1961 - mean_squared_error: 161.1961\n",
      "Epoch 272/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.1559 - mean_squared_error: 161.1559\n",
      "Epoch 273/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.1160 - mean_squared_error: 161.1160\n",
      "Epoch 274/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.0768 - mean_squared_error: 161.0768\n",
      "Epoch 275/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 161.0379 - mean_squared_error: 161.0379\n",
      "Epoch 276/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.9994 - mean_squared_error: 160.9994\n",
      "Epoch 277/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.9613 - mean_squared_error: 160.9613\n",
      "Epoch 278/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.9236 - mean_squared_error: 160.9236\n",
      "Epoch 279/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.8865 - mean_squared_error: 160.8865\n",
      "Epoch 280/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 160.8497 - mean_squared_error: 160.8497\n",
      "Epoch 281/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.8133 - mean_squared_error: 160.8133\n",
      "Epoch 282/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.7772 - mean_squared_error: 160.7772\n",
      "Epoch 283/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.7417 - mean_squared_error: 160.7417\n",
      "Epoch 284/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.7065 - mean_squared_error: 160.7065\n",
      "Epoch 285/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.6718 - mean_squared_error: 160.6718\n",
      "Epoch 286/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.6374 - mean_squared_error: 160.6374\n",
      "Epoch 287/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.6032 - mean_squared_error: 160.6032\n",
      "Epoch 288/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.5696 - mean_squared_error: 160.5696\n",
      "Epoch 289/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.5363 - mean_squared_error: 160.5363\n",
      "Epoch 290/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 160.5034 - mean_squared_error: 160.5034\n",
      "Epoch 291/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.4707 - mean_squared_error: 160.4707\n",
      "Epoch 292/300\n",
      "3/3 [==============================] - 0s 0us/step - loss: 160.4384 - mean_squared_error: 160.4384\n",
      "Epoch 293/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.4066 - mean_squared_error: 160.4066\n",
      "Epoch 294/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.3750 - mean_squared_error: 160.3750\n",
      "Epoch 295/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.3438 - mean_squared_error: 160.3438\n",
      "Epoch 296/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.3128 - mean_squared_error: 160.3128\n",
      "Epoch 297/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.2822 - mean_squared_error: 160.2822\n",
      "Epoch 298/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 160.2520 - mean_squared_error: 160.2520\n",
      "Epoch 299/300\n",
      "3/3 [==============================] - 0s 1ms/step - loss: 160.2220 - mean_squared_error: 160.2220\n",
      "Epoch 300/300\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 160.1925 - mean_squared_error: 160.1925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d52691ba90>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hx=w1x1+w2x2+w3x3+b\n",
    "x=np.array([[100,90,80],[55,45,36],[77,88,90]])#중간,기말,최종\n",
    "y=np.array([92, 70, 88])\n",
    "model=Sequential()\n",
    "model.add(Dense(1, input_dim=3, activation='linear'))\n",
    "sgd=optimizers.SGD(lr=0.00001)\n",
    "model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
    "model.fit(x,y,batch_size=1, epochs=300, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[105.36288],\n",
       "       [ 56.78319],\n",
       "       [ 84.98882]], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x) #[92, 70, 88]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "4/4 [==============================] - 0s 41ms/step - loss: 0.8495 - binary_accuracy: 0.5000\n",
      "Epoch 2/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.8385 - binary_accuracy: 0.2500\n",
      "Epoch 3/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8278 - binary_accuracy: 0.2500\n",
      "Epoch 4/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8174 - binary_accuracy: 0.2500\n",
      "Epoch 5/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.8073 - binary_accuracy: 0.2500\n",
      "Epoch 6/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.7975 - binary_accuracy: 0.2500\n",
      "Epoch 7/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7880 - binary_accuracy: 0.2500\n",
      "Epoch 8/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7787 - binary_accuracy: 0.2500\n",
      "Epoch 9/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.7697 - binary_accuracy: 0.2500\n",
      "Epoch 10/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.7610 - binary_accuracy: 0.2500\n",
      "Epoch 11/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7525 - binary_accuracy: 0.2500\n",
      "Epoch 12/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.7443 - binary_accuracy: 0.2500\n",
      "Epoch 13/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.7363 - binary_accuracy: 0.2500\n",
      "Epoch 14/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.7286 - binary_accuracy: 0.2500\n",
      "Epoch 15/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7210 - binary_accuracy: 0.2500\n",
      "Epoch 16/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.7137 - binary_accuracy: 0.2500\n",
      "Epoch 17/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.7066 - binary_accuracy: 0.2500\n",
      "Epoch 18/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6997 - binary_accuracy: 0.5000\n",
      "Epoch 19/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6930 - binary_accuracy: 0.5000\n",
      "Epoch 20/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6864 - binary_accuracy: 0.5000\n",
      "Epoch 21/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.6801 - binary_accuracy: 0.5000\n",
      "Epoch 22/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6740 - binary_accuracy: 0.5000\n",
      "Epoch 23/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.6680 - binary_accuracy: 0.5000\n",
      "Epoch 24/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6622 - binary_accuracy: 0.5000\n",
      "Epoch 25/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.6565 - binary_accuracy: 0.5000\n",
      "Epoch 26/300\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.6510 - binary_accuracy: 0.5000\n",
      "Epoch 27/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6457 - binary_accuracy: 0.5000\n",
      "Epoch 28/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.6405 - binary_accuracy: 0.5000\n",
      "Epoch 29/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.6354 - binary_accuracy: 0.5000\n",
      "Epoch 30/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6305 - binary_accuracy: 0.5000\n",
      "Epoch 31/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.6258 - binary_accuracy: 0.5000\n",
      "Epoch 32/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6211 - binary_accuracy: 0.5000\n",
      "Epoch 33/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6166 - binary_accuracy: 0.5000\n",
      "Epoch 34/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.6122 - binary_accuracy: 0.7500\n",
      "Epoch 35/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.6079 - binary_accuracy: 0.7500\n",
      "Epoch 36/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6037 - binary_accuracy: 0.7500\n",
      "Epoch 37/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5997 - binary_accuracy: 0.7500\n",
      "Epoch 38/300\n",
      "4/4 [==============================] - 0s 996us/step - loss: 0.5957 - binary_accuracy: 0.7500\n",
      "Epoch 39/300\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.5918 - binary_accuracy: 0.7500\n",
      "Epoch 40/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5881 - binary_accuracy: 0.7500\n",
      "Epoch 41/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5844 - binary_accuracy: 0.7500\n",
      "Epoch 42/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5809 - binary_accuracy: 0.7500\n",
      "Epoch 43/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.5774 - binary_accuracy: 0.7500\n",
      "Epoch 44/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.5740 - binary_accuracy: 0.7500\n",
      "Epoch 45/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.5707 - binary_accuracy: 0.7500\n",
      "Epoch 46/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.5675 - binary_accuracy: 0.7500\n",
      "Epoch 47/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5643 - binary_accuracy: 0.7500\n",
      "Epoch 48/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.5612 - binary_accuracy: 0.7500\n",
      "Epoch 49/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5582 - binary_accuracy: 0.7500\n",
      "Epoch 50/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9109 - binary_accuracy: 0.0000e+0 - 0s 997us/step - loss: 0.5553 - binary_accuracy: 0.7500\n",
      "Epoch 51/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.5524 - binary_accuracy: 0.7500\n",
      "Epoch 52/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.5496 - binary_accuracy: 0.7500\n",
      "Epoch 53/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5469 - binary_accuracy: 0.7500\n",
      "Epoch 54/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5442 - binary_accuracy: 0.7500\n",
      "Epoch 55/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5416 - binary_accuracy: 0.7500\n",
      "Epoch 56/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.5391 - binary_accuracy: 0.7500\n",
      "Epoch 57/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.5366 - binary_accuracy: 0.7500\n",
      "Epoch 58/300\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.5342 - binary_accuracy: 0.7500\n",
      "Epoch 59/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.5318 - binary_accuracy: 0.7500\n",
      "Epoch 60/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5295 - binary_accuracy: 0.7500\n",
      "Epoch 61/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.5272 - binary_accuracy: 0.7500\n",
      "Epoch 62/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.5249 - binary_accuracy: 0.7500\n",
      "Epoch 63/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5227 - binary_accuracy: 0.7500\n",
      "Epoch 64/300\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.5206 - binary_accuracy: 0.7500\n",
      "Epoch 65/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5185 - binary_accuracy: 0.7500\n",
      "Epoch 66/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5165 - binary_accuracy: 0.7500\n",
      "Epoch 67/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5144 - binary_accuracy: 0.7500\n",
      "Epoch 68/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5125 - binary_accuracy: 0.7500\n",
      "Epoch 69/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.5105 - binary_accuracy: 0.7500\n",
      "Epoch 70/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5086 - binary_accuracy: 0.7500\n",
      "Epoch 71/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.5068 - binary_accuracy: 0.7500\n",
      "Epoch 72/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5049 - binary_accuracy: 0.7500\n",
      "Epoch 73/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.5032 - binary_accuracy: 0.7500\n",
      "Epoch 74/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.5014 - binary_accuracy: 0.7500\n",
      "Epoch 75/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4997 - binary_accuracy: 0.7500\n",
      "Epoch 76/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4980 - binary_accuracy: 0.7500\n",
      "Epoch 77/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4963 - binary_accuracy: 0.7500\n",
      "Epoch 78/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4947 - binary_accuracy: 0.7500\n",
      "Epoch 79/300\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.4931 - binary_accuracy: 0.7500\n",
      "Epoch 80/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4915 - binary_accuracy: 0.7500\n",
      "Epoch 81/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.4900 - binary_accuracy: 0.7500\n",
      "Epoch 82/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4884 - binary_accuracy: 0.7500\n",
      "Epoch 83/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4869 - binary_accuracy: 0.7500\n",
      "Epoch 84/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4855 - binary_accuracy: 0.7500\n",
      "Epoch 85/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4840 - binary_accuracy: 0.7500\n",
      "Epoch 86/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4826 - binary_accuracy: 0.7500\n",
      "Epoch 87/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4812 - binary_accuracy: 0.7500\n",
      "Epoch 88/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4798 - binary_accuracy: 0.7500\n",
      "Epoch 89/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4785 - binary_accuracy: 0.7500\n",
      "Epoch 90/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4771 - binary_accuracy: 0.7500\n",
      "Epoch 91/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4758 - binary_accuracy: 0.7500\n",
      "Epoch 92/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4745 - binary_accuracy: 0.7500\n",
      "Epoch 93/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4732 - binary_accuracy: 0.7500\n",
      "Epoch 94/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4720 - binary_accuracy: 0.7500\n",
      "Epoch 95/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4707 - binary_accuracy: 0.7500\n",
      "Epoch 96/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4695 - binary_accuracy: 0.7500\n",
      "Epoch 97/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4683 - binary_accuracy: 0.7500\n",
      "Epoch 98/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4671 - binary_accuracy: 0.7500\n",
      "Epoch 99/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4660 - binary_accuracy: 0.7500\n",
      "Epoch 100/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4648 - binary_accuracy: 0.7500\n",
      "Epoch 101/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4637 - binary_accuracy: 0.7500\n",
      "Epoch 102/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4625 - binary_accuracy: 0.7500\n",
      "Epoch 103/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4614 - binary_accuracy: 0.7500\n",
      "Epoch 104/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4603 - binary_accuracy: 0.7500\n",
      "Epoch 105/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4593 - binary_accuracy: 0.7500\n",
      "Epoch 106/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4582 - binary_accuracy: 0.7500\n",
      "Epoch 107/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4571 - binary_accuracy: 0.7500\n",
      "Epoch 108/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4561 - binary_accuracy: 0.7500\n",
      "Epoch 109/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4551 - binary_accuracy: 0.7500\n",
      "Epoch 110/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.4541 - binary_accuracy: 0.7500\n",
      "Epoch 111/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4531 - binary_accuracy: 0.7500\n",
      "Epoch 112/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4521 - binary_accuracy: 0.7500\n",
      "Epoch 113/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4511 - binary_accuracy: 0.7500\n",
      "Epoch 114/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4501 - binary_accuracy: 0.7500\n",
      "Epoch 115/300\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.4492 - binary_accuracy: 0.7500\n",
      "Epoch 116/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4482 - binary_accuracy: 0.7500\n",
      "Epoch 117/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4473 - binary_accuracy: 0.7500\n",
      "Epoch 118/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4464 - binary_accuracy: 0.7500\n",
      "Epoch 119/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4454 - binary_accuracy: 0.7500\n",
      "Epoch 120/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4445 - binary_accuracy: 0.7500\n",
      "Epoch 121/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4436 - binary_accuracy: 0.7500\n",
      "Epoch 122/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4428 - binary_accuracy: 0.7500\n",
      "Epoch 123/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4419 - binary_accuracy: 0.7500\n",
      "Epoch 124/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4410 - binary_accuracy: 0.7500\n",
      "Epoch 125/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4402 - binary_accuracy: 0.7500\n",
      "Epoch 126/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4393 - binary_accuracy: 0.7500\n",
      "Epoch 127/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4385 - binary_accuracy: 0.7500\n",
      "Epoch 128/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4376 - binary_accuracy: 0.7500\n",
      "Epoch 129/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4368 - binary_accuracy: 0.7500\n",
      "Epoch 130/300\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.4360 - binary_accuracy: 0.7500\n",
      "Epoch 131/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4352 - binary_accuracy: 0.7500\n",
      "Epoch 132/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4344 - binary_accuracy: 0.7500\n",
      "Epoch 133/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4336 - binary_accuracy: 0.7500\n",
      "Epoch 134/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4328 - binary_accuracy: 0.7500\n",
      "Epoch 135/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4320 - binary_accuracy: 0.7500\n",
      "Epoch 136/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4312 - binary_accuracy: 0.7500\n",
      "Epoch 137/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4305 - binary_accuracy: 0.7500\n",
      "Epoch 138/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4297 - binary_accuracy: 0.7500\n",
      "Epoch 139/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4289 - binary_accuracy: 0.7500\n",
      "Epoch 140/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4282 - binary_accuracy: 0.7500\n",
      "Epoch 141/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 1.0037 - binary_accuracy: 0.0000e+0 - 0s 1ms/step - loss: 0.4275 - binary_accuracy: 0.7500\n",
      "Epoch 142/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4267 - binary_accuracy: 0.7500\n",
      "Epoch 143/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4260 - binary_accuracy: 0.7500\n",
      "Epoch 144/300\n",
      "4/4 [==============================] - 0s 0us/step - loss: 0.4253 - binary_accuracy: 0.7500\n",
      "Epoch 145/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4245 - binary_accuracy: 0.7500\n",
      "Epoch 146/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.4238 - binary_accuracy: 0.7500\n",
      "Epoch 147/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4231 - binary_accuracy: 0.7500\n",
      "Epoch 148/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4224 - binary_accuracy: 0.7500\n",
      "Epoch 149/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4217 - binary_accuracy: 0.7500\n",
      "Epoch 150/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4210 - binary_accuracy: 0.7500\n",
      "Epoch 151/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4203 - binary_accuracy: 0.7500\n",
      "Epoch 152/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4197 - binary_accuracy: 0.7500\n",
      "Epoch 153/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4190 - binary_accuracy: 0.7500\n",
      "Epoch 154/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4183 - binary_accuracy: 0.7500\n",
      "Epoch 155/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4176 - binary_accuracy: 0.7500\n",
      "Epoch 156/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4170 - binary_accuracy: 0.7500\n",
      "Epoch 157/300\n",
      "4/4 [==============================] - 0s 0us/step - loss: 0.4163 - binary_accuracy: 0.7500\n",
      "Epoch 158/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4157 - binary_accuracy: 0.7500\n",
      "Epoch 159/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4150 - binary_accuracy: 0.7500\n",
      "Epoch 160/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4144 - binary_accuracy: 0.7500\n",
      "Epoch 161/300\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.4137 - binary_accuracy: 0.7500\n",
      "Epoch 162/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4131 - binary_accuracy: 0.7500\n",
      "Epoch 163/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4124 - binary_accuracy: 0.7500\n",
      "Epoch 164/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4118 - binary_accuracy: 0.7500\n",
      "Epoch 165/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4112 - binary_accuracy: 0.7500\n",
      "Epoch 166/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4106 - binary_accuracy: 0.7500\n",
      "Epoch 167/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9977 - binary_accuracy: 0.0000e+0 - 0s 1ms/step - loss: 0.4099 - binary_accuracy: 0.7500\n",
      "Epoch 168/300\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.4093 - binary_accuracy: 0.7500\n",
      "Epoch 169/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4087 - binary_accuracy: 0.7500\n",
      "Epoch 170/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4081 - binary_accuracy: 0.7500\n",
      "Epoch 171/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4075 - binary_accuracy: 0.7500\n",
      "Epoch 172/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4069 - binary_accuracy: 0.7500\n",
      "Epoch 173/300\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.4063 - binary_accuracy: 0.7500\n",
      "Epoch 174/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4057 - binary_accuracy: 0.7500\n",
      "Epoch 175/300\n",
      "4/4 [==============================] - 0s 0us/step - loss: 0.4051 - binary_accuracy: 0.7500\n",
      "Epoch 176/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4045 - binary_accuracy: 0.7500\n",
      "Epoch 177/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4039 - binary_accuracy: 0.7500\n",
      "Epoch 178/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4034 - binary_accuracy: 0.7500\n",
      "Epoch 179/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4028 - binary_accuracy: 0.7500\n",
      "Epoch 180/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.4022 - binary_accuracy: 0.7500\n",
      "Epoch 181/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4016 - binary_accuracy: 0.7500\n",
      "Epoch 182/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4011 - binary_accuracy: 0.7500\n",
      "Epoch 183/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.4005 - binary_accuracy: 0.7500\n",
      "Epoch 184/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3999 - binary_accuracy: 0.7500\n",
      "Epoch 185/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3994 - binary_accuracy: 0.7500\n",
      "Epoch 186/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3988 - binary_accuracy: 0.7500\n",
      "Epoch 187/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3983 - binary_accuracy: 0.7500\n",
      "Epoch 188/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3977 - binary_accuracy: 0.7500\n",
      "Epoch 189/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3971 - binary_accuracy: 0.7500\n",
      "Epoch 190/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3966 - binary_accuracy: 0.7500\n",
      "Epoch 191/300\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.3960 - binary_accuracy: 0.7500\n",
      "Epoch 192/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3955 - binary_accuracy: 0.7500\n",
      "Epoch 193/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3950 - binary_accuracy: 0.7500\n",
      "Epoch 194/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3944 - binary_accuracy: 0.7500\n",
      "Epoch 195/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3939 - binary_accuracy: 0.7500\n",
      "Epoch 196/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3934 - binary_accuracy: 0.7500\n",
      "Epoch 197/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3928 - binary_accuracy: 0.7500\n",
      "Epoch 198/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3923 - binary_accuracy: 0.7500\n",
      "Epoch 199/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3918 - binary_accuracy: 0.7500\n",
      "Epoch 200/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3912 - binary_accuracy: 0.7500\n",
      "Epoch 201/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3907 - binary_accuracy: 0.7500\n",
      "Epoch 202/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3902 - binary_accuracy: 0.7500\n",
      "Epoch 203/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3897 - binary_accuracy: 0.7500\n",
      "Epoch 204/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3892 - binary_accuracy: 0.7500\n",
      "Epoch 205/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3886 - binary_accuracy: 0.7500\n",
      "Epoch 206/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3881 - binary_accuracy: 0.7500\n",
      "Epoch 207/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3876 - binary_accuracy: 0.7500\n",
      "Epoch 208/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3871 - binary_accuracy: 0.7500\n",
      "Epoch 209/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3866 - binary_accuracy: 0.7500\n",
      "Epoch 210/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3861 - binary_accuracy: 0.7500\n",
      "Epoch 211/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3856 - binary_accuracy: 0.7500\n",
      "Epoch 212/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3851 - binary_accuracy: 0.7500\n",
      "Epoch 213/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3846 - binary_accuracy: 0.7500\n",
      "Epoch 214/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3841 - binary_accuracy: 0.7500\n",
      "Epoch 215/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3836 - binary_accuracy: 0.7500\n",
      "Epoch 216/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3831 - binary_accuracy: 0.7500\n",
      "Epoch 217/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3826 - binary_accuracy: 0.7500\n",
      "Epoch 218/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3821 - binary_accuracy: 0.7500\n",
      "Epoch 219/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3816 - binary_accuracy: 0.7500\n",
      "Epoch 220/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3812 - binary_accuracy: 0.7500\n",
      "Epoch 221/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3807 - binary_accuracy: 0.7500\n",
      "Epoch 222/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3802 - binary_accuracy: 0.7500\n",
      "Epoch 223/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3797 - binary_accuracy: 0.7500\n",
      "Epoch 224/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3792 - binary_accuracy: 0.7500\n",
      "Epoch 225/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3788 - binary_accuracy: 0.7500\n",
      "Epoch 226/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3783 - binary_accuracy: 0.7500\n",
      "Epoch 227/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3778 - binary_accuracy: 0.7500\n",
      "Epoch 228/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3773 - binary_accuracy: 0.7500\n",
      "Epoch 229/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3769 - binary_accuracy: 0.7500\n",
      "Epoch 230/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3764 - binary_accuracy: 0.7500\n",
      "Epoch 231/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3759 - binary_accuracy: 0.7500\n",
      "Epoch 232/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3755 - binary_accuracy: 0.7500\n",
      "Epoch 233/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3750 - binary_accuracy: 0.7500\n",
      "Epoch 234/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3745 - binary_accuracy: 0.7500\n",
      "Epoch 235/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3741 - binary_accuracy: 0.7500\n",
      "Epoch 236/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3736 - binary_accuracy: 0.7500\n",
      "Epoch 237/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3731 - binary_accuracy: 0.7500\n",
      "Epoch 238/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3727 - binary_accuracy: 0.7500\n",
      "Epoch 239/300\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.3722 - binary_accuracy: 0.7500\n",
      "Epoch 240/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3718 - binary_accuracy: 0.7500\n",
      "Epoch 241/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3713 - binary_accuracy: 0.7500\n",
      "Epoch 242/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3709 - binary_accuracy: 0.7500\n",
      "Epoch 243/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3704 - binary_accuracy: 0.7500\n",
      "Epoch 244/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3700 - binary_accuracy: 0.7500\n",
      "Epoch 245/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3695 - binary_accuracy: 0.7500\n",
      "Epoch 246/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3691 - binary_accuracy: 0.7500\n",
      "Epoch 247/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3686 - binary_accuracy: 0.7500\n",
      "Epoch 248/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3682 - binary_accuracy: 0.7500\n",
      "Epoch 249/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3677 - binary_accuracy: 0.7500\n",
      "Epoch 250/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3673 - binary_accuracy: 0.7500\n",
      "Epoch 251/300\n",
      "4/4 [==============================] - ETA: 0s - loss: 0.9428 - binary_accuracy: 0.0000e+0 - 0s 1000us/step - loss: 0.3668 - binary_accuracy: 0.7500\n",
      "Epoch 252/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3664 - binary_accuracy: 0.7500\n",
      "Epoch 253/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3660 - binary_accuracy: 0.7500\n",
      "Epoch 254/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3655 - binary_accuracy: 0.7500\n",
      "Epoch 255/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3651 - binary_accuracy: 0.7500\n",
      "Epoch 256/300\n",
      "4/4 [==============================] - 0s 999us/step - loss: 0.3647 - binary_accuracy: 0.7500\n",
      "Epoch 257/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3642 - binary_accuracy: 0.7500\n",
      "Epoch 258/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3638 - binary_accuracy: 0.7500\n",
      "Epoch 259/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3634 - binary_accuracy: 0.7500\n",
      "Epoch 260/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3629 - binary_accuracy: 0.7500\n",
      "Epoch 261/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3625 - binary_accuracy: 0.7500\n",
      "Epoch 262/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3621 - binary_accuracy: 0.7500\n",
      "Epoch 263/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3616 - binary_accuracy: 0.7500\n",
      "Epoch 264/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3612 - binary_accuracy: 0.7500\n",
      "Epoch 265/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3608 - binary_accuracy: 0.7500\n",
      "Epoch 266/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3604 - binary_accuracy: 0.7500\n",
      "Epoch 267/300\n",
      "4/4 [==============================] - 0s 997us/step - loss: 0.3600 - binary_accuracy: 0.7500\n",
      "Epoch 268/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3595 - binary_accuracy: 0.7500\n",
      "Epoch 269/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3591 - binary_accuracy: 0.7500\n",
      "Epoch 270/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3587 - binary_accuracy: 0.7500\n",
      "Epoch 271/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3583 - binary_accuracy: 0.7500\n",
      "Epoch 272/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3579 - binary_accuracy: 0.7500\n",
      "Epoch 273/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3574 - binary_accuracy: 0.7500\n",
      "Epoch 274/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3570 - binary_accuracy: 0.7500\n",
      "Epoch 275/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3566 - binary_accuracy: 0.7500\n",
      "Epoch 276/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3562 - binary_accuracy: 0.7500\n",
      "Epoch 277/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3558 - binary_accuracy: 0.7500\n",
      "Epoch 278/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3554 - binary_accuracy: 0.7500\n",
      "Epoch 279/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3550 - binary_accuracy: 0.7500\n",
      "Epoch 280/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3546 - binary_accuracy: 0.7500\n",
      "Epoch 281/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3542 - binary_accuracy: 0.7500\n",
      "Epoch 282/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3537 - binary_accuracy: 0.7500\n",
      "Epoch 283/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3533 - binary_accuracy: 0.7500\n",
      "Epoch 284/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3529 - binary_accuracy: 0.7500\n",
      "Epoch 285/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3525 - binary_accuracy: 0.7500\n",
      "Epoch 286/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3521 - binary_accuracy: 0.7500\n",
      "Epoch 287/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3517 - binary_accuracy: 0.7500\n",
      "Epoch 288/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3513 - binary_accuracy: 0.7500\n",
      "Epoch 289/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3509 - binary_accuracy: 0.7500\n",
      "Epoch 290/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3505 - binary_accuracy: 0.7500\n",
      "Epoch 291/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3501 - binary_accuracy: 0.7500\n",
      "Epoch 292/300\n",
      "4/4 [==============================] - 0s 998us/step - loss: 0.3497 - binary_accuracy: 0.7500\n",
      "Epoch 293/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3493 - binary_accuracy: 0.7500\n",
      "Epoch 294/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3489 - binary_accuracy: 0.7500\n",
      "Epoch 295/300\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3485 - binary_accuracy: 0.7500\n",
      "Epoch 296/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3482 - binary_accuracy: 0.7500\n",
      "Epoch 297/300\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3478 - binary_accuracy: 0.7500\n",
      "Epoch 298/300\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.3474 - binary_accuracy: 0.7500\n",
      "Epoch 299/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3470 - binary_accuracy: 0.7500\n",
      "Epoch 300/300\n",
      "4/4 [==============================] - 0s 1000us/step - loss: 0.3466 - binary_accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d52675f748>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#다중 로지스틱 회귀\n",
    "x=np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y=np.array([0,1,1,1])\n",
    "model=Sequential()\n",
    "model.add(Dense(1, input_dim=2, activation='sigmoid'))\n",
    "sgd=optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "model.fit(x,y,batch_size=1, epochs=300, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.59313333],\n",
       "       [0.84702414],\n",
       "       [0.78139937],\n",
       "       [0.9313974 ]], dtype=float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#소프트맥스 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'data/iris.csv' does not exist: b'data/iris.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-5640bfbcbba8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/iris.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'data/iris.csv' does not exist: b'data/iris.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"data/iris.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
