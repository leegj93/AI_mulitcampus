{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import *\n",
    "from keras.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]],\n",
       "\n",
       "       [[13, 14, 15],\n",
       "        [16, 17, 18]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rnn -> (batchsize, timestep, inputdim)\n",
    "x=np.array([[[1,2,3], [4,5,6]],\n",
    "         [[7,8,9], [10,11,12]],\n",
    "         [[13,14,15], [16,17,18]]])\n",
    "x\n",
    "#rnn->(batchsize(3),timesteps(2),inputdim(3))\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 50)\n"
     ]
    }
   ],
   "source": [
    "#simple rnn: 2개의 (timesteps, inputdim)\n",
    "rnn=SimpleRNN(50)(Input(shape=(10,30)))\n",
    "#                        (timestep, inputdim)\n",
    "#return_sequences = False로 디폴트 설정\n",
    "#=> 출력 값이 셀의 개수와 동일, 셀 하나당\n",
    "#하나의 스칼라값이 리턴\n",
    "print(rnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, ?, 50)\n"
     ]
    }
   ],
   "source": [
    "#simple rnn: 2개의 (timesteps, inputdim)\n",
    "rnn=SimpleRNN(50,return_sequences = True )(Input(shape=(10,30)))\n",
    "#                        (timestep, inputdim)\n",
    "#return_sequences = True로 설정\n",
    "#timestep * num of cell 개가 출력\n",
    "print(rnn.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"simple_rnn_8/TensorArrayReadV3:0\", shape=(?, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "rnn=SimpleRNN(50, return_sequences=False)(Input(shape=(10,30)))\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"simple_rnn_9/transpose_1:0\", shape=(?, ?, 50), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "rnn=SimpleRNN(50, return_sequences=True)(Input(shape=(10,30)))\n",
    "print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot_data=pd.read_csv(\"ChatbotData.csv\")\n",
    "question, answer=list(chatbot_data['Q']),list(chatbot_data['A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#한 문장에서 단어 시퀀스의 최대 개수\n",
    "max_sequences=30\n",
    "\n",
    "#임베딩 벡터 차원\n",
    "embedding_dim=100\n",
    "# [0 0 1 0 .... 0 0 0] => [1.5 2.7 3.8 1.7...]\n",
    "#  <----450여개---->      <------100개------>\n",
    "\n",
    "#LSTM 히든레이어 차원\n",
    "lstm_hidden_dim=128\n",
    "\n",
    "#정규표현식 필터\n",
    "RE_FILTER=re.compile(\"[.,!?\\\"':;~()]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD=\"<PADDING>\" #패딩\n",
    "STA=\"<START>\" #시작\n",
    "END=\"<END>\" #끝\n",
    "OOV=\"<OOV>\" #없는 단어\n",
    "\n",
    "#태그 문자에 대한 인덱스 정의\n",
    "PAD_INDEX=0\n",
    "STA_INDEX=1\n",
    "END_INDEX=2\n",
    "OOV_INDEX=3\n",
    "\n",
    "#데이터 타입\n",
    "ENCODER_INPUT=0\n",
    "DECODER_INPUT=1\n",
    "DECODER_TARGET=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                      잘   가   eos (DECODER_TARGET)\n",
    "# 안   녕   하 세 요\n",
    "# 인코더         ->       디코더\n",
    "# hello(ENCODER_INPUT) STA  잘   가 (DECODER_INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11823"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "question=question[:100]\n",
    "answer=answer[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qustion:12시 땡!\n",
      "answer:하루가 또 가네요.\n",
      "\n",
      "Qustion:1지망 학교 떨어졌어\n",
      "answer:위로해 드립니다.\n",
      "\n",
      "Qustion:3박4일 놀러가고 싶다\n",
      "answer:여행은 언제나 좋죠.\n",
      "\n",
      "Qustion:3박4일 정도 놀러가고 싶다\n",
      "answer:여행은 언제나 좋죠.\n",
      "\n",
      "Qustion:PPL 심하네\n",
      "answer:눈살이 찌푸려지죠.\n",
      "\n",
      "Qustion:SD카드 망가졌어\n",
      "answer:다시 새로 사는 게 마음 편해요.\n",
      "\n",
      "Qustion:SD카드 안돼\n",
      "answer:다시 새로 사는 게 마음 편해요.\n",
      "\n",
      "Qustion:SNS 맞팔 왜 안하지ㅠㅠ\n",
      "answer:잘 모르고 있을 수도 있어요.\n",
      "\n",
      "Qustion:SNS 시간낭비인 거 아는데 매일 하는 중\n",
      "answer:시간을 정하고 해보세요.\n",
      "\n",
      "Qustion:SNS 시간낭비인데 자꾸 보게됨\n",
      "answer:시간을 정하고 해보세요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Qustion:\" + question[i])\n",
    "    print(\"answer:\" + answer[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. 단어사전 생성\n",
    "#문장 -> 토큰(글자, 단어, 문장) 분리 -> KoNLPy(한국어) -> 형태소분석기(한나눔, 코모란, Okt 등)\n",
    "#KoNLPy(자바로 작성되어있음) 사용하기 위해 \n",
    "#1)java설치(>=1.7)->환경변수 이름:JAVA_HOME, 값:c:\\program files\\jdk....\n",
    "#2)jpype1 설치(파이썬에서 자바를 호출할 수 있도록 하는 라이브러리)  #아나콘다 프롬프트 -> pip install jpype파일저장경로\n",
    "#3)KoNLPy 설치 => 아나콘다 프롬프트 -> pip install KoNLPy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#형태소 분석 함수\n",
    "def pos_tag(sentences):\n",
    "    tagger=Okt()\n",
    "    sentences_pos=[]\n",
    "    for sentence in sentences:\n",
    "        sentence=re.sub(RE_FILTER,\"\",sentence)\n",
    "        sentence=\" \".join(tagger.morphs(sentence))\n",
    "        sentences_pos.append(sentence)\n",
    "    #print(sentences_pos)\n",
    "    return sentences_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['하루 가 또 가네요',\n",
       " '위로 해 드립니다',\n",
       " '여행 은 언제나 좋죠',\n",
       " '여행 은 언제나 좋죠',\n",
       " '눈살 이 찌푸려지죠',\n",
       " '다시 새로 사는 게 마음 편해요',\n",
       " '다시 새로 사는 게 마음 편해요',\n",
       " '잘 모르고 있을 수도 있어요',\n",
       " '시간 을 정 하고 해보세요',\n",
       " '시간 을 정 하고 해보세요',\n",
       " '자랑 하는 자리 니까 요',\n",
       " '그 사람 도 그럴 거 예요',\n",
       " '그 사람 도 그럴 거 예요',\n",
       " '혼자 를 즐기세요',\n",
       " '돈 은 다시 들어올 거 예요',\n",
       " '땀 을 식혀주세요',\n",
       " '어서 잊고 새 출발 하세요',\n",
       " '빨리 집 에 돌아가서 끄고 나오세요',\n",
       " '빨리 집 에 돌아가서 끄고 나오세요',\n",
       " '다음 달 에는 더 절약 해봐요',\n",
       " '따뜻하게 사세요',\n",
       " '다음 달 에는 더 절약 해봐요',\n",
       " '가장 확실한 시간 은 오늘이 에요 어제 와 내일 을 놓고 고민 하느라 시간 을 낭비하지 마세요',\n",
       " '온 가족 이 모두 마음 에 드는 곳 으로 가보세요',\n",
       " '온 가족 이 모두 마음 에 드는 곳 으로 가보세요',\n",
       " '온 가족 이 모두 마음 에 드는 곳 으로 가보세요',\n",
       " '저 를 만들어 준 사람 을 부모님 저 랑 이야기 해 주는 사람 을 친구 로 생각 하고 있어요',\n",
       " '저 를 만들어 준 사람 을 부모님 저 랑 이야기 해 주는 사람 을 친구 로 생각 하고 있어요',\n",
       " '더 가까워질 기회 가 되겠네요',\n",
       " '저 도 요',\n",
       " '다 들 바빠서 이야기 할 시간 이 부족했나 봐요',\n",
       " '다 들 바빠서 이야기 할 시간 이 부족했나 봐요',\n",
       " '온 가족 이 모두 마음 에 드는 곳 으로 가보세요',\n",
       " '좋은 생각 이에요',\n",
       " '더 가까워질 기회 가 되겠네요',\n",
       " '저 를 만들어 준 사람 을 부모님 저 랑 이야기 해 주는 사람 을 친구 로 생각 하고 있어요',\n",
       " '좋은 생각 이에요',\n",
       " '정말 후회 할 습관 이에요',\n",
       " '무모한 결정 을 내 리지 마세요',\n",
       " '선생님 이나 기관 에 연락 해보세요',\n",
       " '떨리는 감정 은 그 자체 로 소중해요',\n",
       " '득템 했길 바라요',\n",
       " '휴식 도 필요하죠',\n",
       " '단 짠으로 두 개 사는게 진리 죠',\n",
       " '단 짠으로 두 개 사는게 진리 죠',\n",
       " '맛있게 드세요',\n",
       " '저 도 싫어요',\n",
       " '가세 요',\n",
       " '가세 요',\n",
       " '맛있게 드세요',\n",
       " '맛있게 드세요',\n",
       " '병원 가세 요',\n",
       " '이럴 때 잘 쉬는 게 중요해요',\n",
       " '이럴 때 잘 쉬는 게 중요해요',\n",
       " '이럴 때 잘 쉬는 게 중요해요',\n",
       " '따뜻하게 관리 하세요',\n",
       " '병원 가세 요',\n",
       " '병원 가세 요',\n",
       " '저 도 듣고 싶네요',\n",
       " '자신 을 더 사랑 해주세요',\n",
       " '그건 습관 이에요',\n",
       " '그건 습관 이에요',\n",
       " '콕 집어서 물어보세요',\n",
       " '좋은 생각 만 하세요',\n",
       " '마음 이 아픈가요',\n",
       " '갑작스러웠나 봐요',\n",
       " '관계 의 변화 가 왔나 봅니다',\n",
       " '처음 3초 가 중요해요 당신 의 매력 을 어필 해보세요',\n",
       " '책임질 수 있을 때 키워 보세요',\n",
       " '먼저 생활 패턴 을 살펴 보세요',\n",
       " '먼저 생활 패턴 을 살펴 보세요',\n",
       " '책임질 수 있을 때 키워 보세요',\n",
       " '아름다운 곳 이 죠',\n",
       " '안 될 것 도 없죠',\n",
       " '혼자 도 좋아요',\n",
       " '연인 은 살쪄도 잘 알아차리지 못 하고 알아차려도 싫어하지 않을 거 예요',\n",
       " '즐거운 시간 보내고 오세요',\n",
       " '질질 끌 지 마세요',\n",
       " '말 해보세요',\n",
       " '함께 하면 서로 를 더 많이 알 게 될 거 예요',\n",
       " '개시 해보세요',\n",
       " '개시 해보세요',\n",
       " '곧 방학 이 예요',\n",
       " '방학 이 참 짧죠',\n",
       " '벗어나는 게 좋겠네요',\n",
       " '벗어나는 게 좋겠네요',\n",
       " '세수 하고 오세요',\n",
       " '그게 제일 중요한 건데 요',\n",
       " '그게 제일 중요한 건데 요',\n",
       " '다음 부터는 더 많이 아세요',\n",
       " '갑작스러웠나 봐요',\n",
       " '공적 인 일 부터 하세요',\n",
       " '공적 인 일 부터 하세요',\n",
       " '낮잠 을 잠깐 자도 괜찮아요',\n",
       " '저 도 좋아해주세요',\n",
       " '친구 들 이 보고싶었나 봐요',\n",
       " '되도록 만나지 마세요',\n",
       " '당신 이 요',\n",
       " '당신 의 운 을 믿어 보세요',\n",
       " '일 못 하는 사람 이 있으면 옆 에 있는 사람 이 더 힘들죠']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=pos_tag(question)\n",
    "question\n",
    "answer=pos_tag(answer)\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qustion:12시 땡\n",
      "answer:하루 가 또 가네요\n",
      "\n",
      "Qustion:1 지망 학교 떨어졌어\n",
      "answer:위로 해 드립니다\n",
      "\n",
      "Qustion:3 박 4일 놀러 가고 싶다\n",
      "answer:여행 은 언제나 좋죠\n",
      "\n",
      "Qustion:3 박 4일 정도 놀러 가고 싶다\n",
      "answer:여행 은 언제나 좋죠\n",
      "\n",
      "Qustion:PPL 심하네\n",
      "answer:눈살 이 찌푸려지죠\n",
      "\n",
      "Qustion:SD 카드 망가졌어\n",
      "answer:다시 새로 사는 게 마음 편해요\n",
      "\n",
      "Qustion:SD 카드 안 돼\n",
      "answer:다시 새로 사는 게 마음 편해요\n",
      "\n",
      "Qustion:SNS 맞팔 왜 안 하지 ㅠㅠ\n",
      "answer:잘 모르고 있을 수도 있어요\n",
      "\n",
      "Qustion:SNS 시간 낭비 인 거 아는데 매일 하는 중\n",
      "answer:시간 을 정 하고 해보세요\n",
      "\n",
      "Qustion:SNS 시간 낭비 인데 자꾸 보게 됨\n",
      "answer:시간 을 정 하고 해보세요\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(\"Qustion:\" + question[i])\n",
    "    print(\"answer:\" + answer[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[]\n",
    "sentences.extend(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12시 땡',\n",
       " '1 지망 학교 떨어졌어',\n",
       " '3 박 4일 놀러 가고 싶다',\n",
       " '3 박 4일 정도 놀러 가고 싶다',\n",
       " 'PPL 심하네',\n",
       " 'SD 카드 망가졌어',\n",
       " 'SD 카드 안 돼',\n",
       " 'SNS 맞팔 왜 안 하지 ㅠㅠ',\n",
       " 'SNS 시간 낭비 인 거 아는데 매일 하는 중',\n",
       " 'SNS 시간 낭비 인데 자꾸 보게 됨',\n",
       " 'SNS 보면 나 만 빼고 다 행복 해보여',\n",
       " '가끔 궁금해',\n",
       " '가끔 뭐 하는지 궁금해',\n",
       " '가끔 은 혼자 인게 좋다',\n",
       " '가난한 자의 설움',\n",
       " '가만 있어도 땀 난다',\n",
       " '가상 화폐 쫄딱 망함',\n",
       " '가스 불 켜고 나갔어',\n",
       " '가스 불 켜놓고 나온거 같아',\n",
       " '가스 비 너무 많이 나왔다',\n",
       " '가스 비 비싼데 감기 걸리겠어',\n",
       " '가스 비 장난 아님',\n",
       " '가장 확실한 건 뭘 까',\n",
       " '가족 여행 가기 로 했어',\n",
       " '가족 여행 고고',\n",
       " '가족 여행 어디 로 가지',\n",
       " '가족 있어',\n",
       " '가족 관계 알려 줘',\n",
       " '가족 끼리 여행 간다',\n",
       " '가족 들 보고 싶어',\n",
       " '가족 들 이랑 서먹해',\n",
       " '가족 들 이랑 서먹해졌어',\n",
       " '가족 들 이랑 어디 가지',\n",
       " '가족 들 이랑 여행 갈거야',\n",
       " '가족 여행 가야 지',\n",
       " '가족 이 누구 야',\n",
       " '가족 이랑 여행 가려고',\n",
       " '가족 한테 스트레스 풀었어',\n",
       " '가출 할까',\n",
       " '가출 해도 갈 데 가 없어',\n",
       " '간만 에 떨리니까 좋더라',\n",
       " '간만 에 쇼핑 중',\n",
       " '간만 에 휴식 중',\n",
       " '간식 뭐 먹을까',\n",
       " '간식 추천',\n",
       " '간장 치킨 시켜야지',\n",
       " '간접흡연 싫어',\n",
       " '갈까 말까 고민 돼',\n",
       " '갈까 말까',\n",
       " '감 말랭이 먹고 싶다',\n",
       " '감 말랭이 먹어야지',\n",
       " '감기 같 애',\n",
       " '감기 걸린 것 같아',\n",
       " '감기 기운 이 있어',\n",
       " '감기 들 거 같 애',\n",
       " '감기 가 오려나',\n",
       " '감기 약 이 없어',\n",
       " '감기 인거 같 애',\n",
       " '감미로운 목소리 좋아',\n",
       " '감정 이 쓰레기통 처럼 엉망 진창 이야',\n",
       " '감정 컨트롤 을 못 하겠어',\n",
       " '감정 컨트롤 이 안 돼',\n",
       " '감히 나를 무시 하는 애가 있어',\n",
       " '갑자기 나쁜 생각 이 막 들더라',\n",
       " '갑자기 눈물 나',\n",
       " '갑자기 물어봐서 당황 했어',\n",
       " '갑자기 불편한 사이 가 된 거 같아',\n",
       " '강렬한 첫인상 남겨야 하는데',\n",
       " '강아지 키우고 싶어',\n",
       " '강아지 키우고 싶은데 역시 안 돼겠지',\n",
       " '강아지 키울 수 있을까',\n",
       " '강아지 키울까',\n",
       " '강원도 가서 살까',\n",
       " '같이 게임 하자고 해도 되나',\n",
       " '같이 놀러 갈 친구 가 없어',\n",
       " '같이 먹었는데 나 만 살찐 거 같아',\n",
       " '같이 수영장 가기 로 했어',\n",
       " '같이 있으면 힘든데 붙잡고 싶어',\n",
       " '같이 피 씨방 가자고 해볼까',\n",
       " '같이 할 수 있는 취미 생활 뭐 있을까',\n",
       " '개강 룩 입어볼까',\n",
       " '개강 옷 예쁘게 입어 볼까',\n",
       " '개강 이다',\n",
       " '개강 이라니',\n",
       " '개 같은 상황',\n",
       " '개 같이 되 버렸어',\n",
       " '개 기름 꼈어',\n",
       " '개념 도 놓고 옴',\n",
       " '개념 이 없어',\n",
       " '개 당황',\n",
       " '개 당황 했잖아 갑자기 물어 봐서',\n",
       " '개인 적 인 업무 까지 다 시켜',\n",
       " '개인 적 인 일도 다 시켜',\n",
       " '개 졸려',\n",
       " '개 좋아',\n",
       " '개학 하 니까 좋다',\n",
       " '걔 너무 싫다',\n",
       " '걔 는 누굴 닮아서 그런거니',\n",
       " '걔 랑 같은 반 됐으면 좋겠다',\n",
       " '거지 같이 일해 놓고 갔어',\n",
       " '하루 가 또 가네요',\n",
       " '위로 해 드립니다',\n",
       " '여행 은 언제나 좋죠',\n",
       " '여행 은 언제나 좋죠',\n",
       " '눈살 이 찌푸려지죠',\n",
       " '다시 새로 사는 게 마음 편해요',\n",
       " '다시 새로 사는 게 마음 편해요',\n",
       " '잘 모르고 있을 수도 있어요',\n",
       " '시간 을 정 하고 해보세요',\n",
       " '시간 을 정 하고 해보세요',\n",
       " '자랑 하는 자리 니까 요',\n",
       " '그 사람 도 그럴 거 예요',\n",
       " '그 사람 도 그럴 거 예요',\n",
       " '혼자 를 즐기세요',\n",
       " '돈 은 다시 들어올 거 예요',\n",
       " '땀 을 식혀주세요',\n",
       " '어서 잊고 새 출발 하세요',\n",
       " '빨리 집 에 돌아가서 끄고 나오세요',\n",
       " '빨리 집 에 돌아가서 끄고 나오세요',\n",
       " '다음 달 에는 더 절약 해봐요',\n",
       " '따뜻하게 사세요',\n",
       " '다음 달 에는 더 절약 해봐요',\n",
       " '가장 확실한 시간 은 오늘이 에요 어제 와 내일 을 놓고 고민 하느라 시간 을 낭비하지 마세요',\n",
       " '온 가족 이 모두 마음 에 드는 곳 으로 가보세요',\n",
       " '온 가족 이 모두 마음 에 드는 곳 으로 가보세요',\n",
       " '온 가족 이 모두 마음 에 드는 곳 으로 가보세요',\n",
       " '저 를 만들어 준 사람 을 부모님 저 랑 이야기 해 주는 사람 을 친구 로 생각 하고 있어요',\n",
       " '저 를 만들어 준 사람 을 부모님 저 랑 이야기 해 주는 사람 을 친구 로 생각 하고 있어요',\n",
       " '더 가까워질 기회 가 되겠네요',\n",
       " '저 도 요',\n",
       " '다 들 바빠서 이야기 할 시간 이 부족했나 봐요',\n",
       " '다 들 바빠서 이야기 할 시간 이 부족했나 봐요',\n",
       " '온 가족 이 모두 마음 에 드는 곳 으로 가보세요',\n",
       " '좋은 생각 이에요',\n",
       " '더 가까워질 기회 가 되겠네요',\n",
       " '저 를 만들어 준 사람 을 부모님 저 랑 이야기 해 주는 사람 을 친구 로 생각 하고 있어요',\n",
       " '좋은 생각 이에요',\n",
       " '정말 후회 할 습관 이에요',\n",
       " '무모한 결정 을 내 리지 마세요',\n",
       " '선생님 이나 기관 에 연락 해보세요',\n",
       " '떨리는 감정 은 그 자체 로 소중해요',\n",
       " '득템 했길 바라요',\n",
       " '휴식 도 필요하죠',\n",
       " '단 짠으로 두 개 사는게 진리 죠',\n",
       " '단 짠으로 두 개 사는게 진리 죠',\n",
       " '맛있게 드세요',\n",
       " '저 도 싫어요',\n",
       " '가세 요',\n",
       " '가세 요',\n",
       " '맛있게 드세요',\n",
       " '맛있게 드세요',\n",
       " '병원 가세 요',\n",
       " '이럴 때 잘 쉬는 게 중요해요',\n",
       " '이럴 때 잘 쉬는 게 중요해요',\n",
       " '이럴 때 잘 쉬는 게 중요해요',\n",
       " '따뜻하게 관리 하세요',\n",
       " '병원 가세 요',\n",
       " '병원 가세 요',\n",
       " '저 도 듣고 싶네요',\n",
       " '자신 을 더 사랑 해주세요',\n",
       " '그건 습관 이에요',\n",
       " '그건 습관 이에요',\n",
       " '콕 집어서 물어보세요',\n",
       " '좋은 생각 만 하세요',\n",
       " '마음 이 아픈가요',\n",
       " '갑작스러웠나 봐요',\n",
       " '관계 의 변화 가 왔나 봅니다',\n",
       " '처음 3초 가 중요해요 당신 의 매력 을 어필 해보세요',\n",
       " '책임질 수 있을 때 키워 보세요',\n",
       " '먼저 생활 패턴 을 살펴 보세요',\n",
       " '먼저 생활 패턴 을 살펴 보세요',\n",
       " '책임질 수 있을 때 키워 보세요',\n",
       " '아름다운 곳 이 죠',\n",
       " '안 될 것 도 없죠',\n",
       " '혼자 도 좋아요',\n",
       " '연인 은 살쪄도 잘 알아차리지 못 하고 알아차려도 싫어하지 않을 거 예요',\n",
       " '즐거운 시간 보내고 오세요',\n",
       " '질질 끌 지 마세요',\n",
       " '말 해보세요',\n",
       " '함께 하면 서로 를 더 많이 알 게 될 거 예요',\n",
       " '개시 해보세요',\n",
       " '개시 해보세요',\n",
       " '곧 방학 이 예요',\n",
       " '방학 이 참 짧죠',\n",
       " '벗어나는 게 좋겠네요',\n",
       " '벗어나는 게 좋겠네요',\n",
       " '세수 하고 오세요',\n",
       " '그게 제일 중요한 건데 요',\n",
       " '그게 제일 중요한 건데 요',\n",
       " '다음 부터는 더 많이 아세요',\n",
       " '갑작스러웠나 봐요',\n",
       " '공적 인 일 부터 하세요',\n",
       " '공적 인 일 부터 하세요',\n",
       " '낮잠 을 잠깐 자도 괜찮아요',\n",
       " '저 도 좋아해주세요',\n",
       " '친구 들 이 보고싶었나 봐요',\n",
       " '되도록 만나지 마세요',\n",
       " '당신 이 요',\n",
       " '당신 의 운 을 믿어 보세요',\n",
       " '일 못 하는 사람 이 있으면 옆 에 있는 사람 이 더 힘들죠']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.extend(answer)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "for sentence in sentences:\n",
    "    for word in sentence.split():\n",
    "        words.append(word)\n",
    "\n",
    "        #길이가 0인 단어는 제거\n",
    "words=[word for word in words if len(word)>0]\n",
    "\n",
    "#중복된 단어 제거\n",
    "words=list(set(words))\n",
    "len(words)\n",
    "#가장 앞부분에 태그 삽입\n",
    "words[:0]=[PAD, STA, END, OOV]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "words\n",
    "#단어 <-> 인덱스로 구성된 딕셔너리\n",
    "word_to_index={word:index for index, word in enumerate(words)}\n",
    "index_to_word={index:word for index, word in enumerate(words)}\n",
    "# word_to_index={'<PADDING>':0, ...}   \n",
    "# index_to_word={0:'<PADDING>', ...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, '<PADDING>'),\n",
       " (1, '<START>'),\n",
       " (2, '<END>'),\n",
       " (3, '<OOV>'),\n",
       " (4, '진리'),\n",
       " (5, '뭘'),\n",
       " (6, '후회'),\n",
       " (7, '됐으면'),\n",
       " (8, '고민'),\n",
       " (9, '감'),\n",
       " (10, '봅니다'),\n",
       " (11, '인'),\n",
       " (12, '죠'),\n",
       " (13, '씨방'),\n",
       " (14, '봐요'),\n",
       " (15, '드는'),\n",
       " (16, '잘'),\n",
       " (17, '있을'),\n",
       " (18, '자꾸'),\n",
       " (19, '상황')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word_to_index.items())[:20]\n",
    "list(index_to_word.items())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq2seq는 학습시 아래와 같은 3개의 데이터가 필요\n",
    "#인코더 입력:12시 땡\n",
    "#디코더 입력:start 점심먹으러 가요\n",
    "#디코더 출력:점심먹으러 가요 end\n",
    "#훈련 모델과 예측 모델이 따로 구성되어야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_index(sentences,vocabulary,type):\n",
    "    sentences_index=[]\n",
    "    for sentence in sentences:\n",
    "        sentence_index=[]        \n",
    "        #디코더 입력-> 맨 앞에 START 추가\n",
    "        if type==DECODER_INPUT:\n",
    "            sentence_index.extend([vocabulary[STA]])\n",
    "        for word in sentence.split():\n",
    "            #사전에 있는 단어면 인덱스 추가\n",
    "            if vocabulary.get(word) is not None:\n",
    "                sentence_index.extend([vocabulary[word]])\n",
    "            else:\n",
    "                sentence_index.extend([vocabulary[OOV]])\n",
    "        \n",
    "        if type==DECODER_TARGET:\n",
    "            #DECODER_TARGET -> 맨 뒤에 END 추가\n",
    "            if len(sentence_index) >= max_sequences:\n",
    "                sentence_index=sentence_index[:max_sequences-1]+[vocabulary[END]]\n",
    "            else:\n",
    "                sentence_index+=[vocabulary[END]]\n",
    "        else:\n",
    "            if len(sentence_index) > max_sequences:\n",
    "                sentence_index= sentence_index[:max_sequences]\n",
    "        sentence_index+=(max_sequences-len(sentence_index))*[vocabulary[PAD]]\n",
    "        sentences_index.append(sentence_index)\n",
    "    return np.asarray(sentences_index)                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 41, 298,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_encoder=convert_text_to_index(question, word_to_index, ENCODER_INPUT) #문장 -> 인덱스\n",
    "x_encoder[0] #전체 문장에 대한 인덱스 변환 결과가 출력\n",
    "#12시 땡 -> [5, 80, 0, 0, ... , 0]\n",
    "#한 문장에서 단어 시퀀스의 최대 개수:max_sequences=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1, 180, 370,  71, 213,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#디코더 입력 인덱스 변환\n",
    "x_decoder=convert_text_to_index(answer, word_to_index, DECODER_INPUT) #문장 -> 인덱스\n",
    "x_decoder[0] #start 점심먹으러 가요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([180, 370,  71, 213,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#디코더 target(목표) 인덱스 변환\n",
    "y_decoder=convert_text_to_index(answer, word_to_index, DECODER_TARGET) #문장 -> 인덱스\n",
    "y_decoder[0] #점심먹으러 가요 end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 전처리(문장 -> 인덱스 변환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#인코더입력, 디코더입력은 임베딩계층에 들어가는 인덱스 배열\n",
    "#디코더출력은 원핫인코딩 형식으로 출력\n",
    "len(y_decoder)  #(100,30,455)\n",
    "#100:답변문장의 개수, 30:시퀀스 길이, 455:전체단어 개수(중복제외\n",
    "one_hot_data=np.zeros((len(y_decoder), max_sequences, len(words)))\n",
    "#디코더 target을 원핫인코딩으로 변환\n",
    "#학습할때는 입력은 인덱스, 출력은 원핫인코딩 형식\n",
    "one_hot_data.shape# (100(문장,i),30(단어개수,j),455(index))  #455 => 원핫인코딩\n",
    "for i, sequence in enumerate(y_decoder):\n",
    "    #print(i)\n",
    "     for j, index in enumerate(sequence):\n",
    "            #print(index)\n",
    "            one_hot_data[i,j,index]=1\n",
    "y_decoder=one_hot_data\n",
    "y_decoder[0]  #(100,30,455)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0911 10:47:00.050635   244 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0911 10:47:00.064656   244 deprecation_wrapper.py:119] From C:\\Users\\user\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#훈련 모델 정의\n",
    "\n",
    "#훈련 모델 인코더 정의:입력 문장의 인덱스 시퀀스를 입력으로 받음\n",
    "encoder_inputs=Input(shape=(None,))\n",
    "#임베딩 계층\n",
    "encoder_outputs=Embedding(len(words), embedding_dim)(encoder_inputs)\n",
    "encoder_outputs, state_h, state_c=LSTM(lstm_hidden_dim,\n",
    "    dropout=0.1,\n",
    "    return_state=True)(encoder_outputs)\n",
    "\n",
    "encoder_states=[state_h, state_c]\n",
    "\n",
    "\n",
    "#훈련 모델 디코더 정의:목표 문장의 시퀀스를 입력으로 받음\n",
    "decoder_inputs=Input(shape=(None,))\n",
    "decoder_embedding=Embedding(len(words), embedding_dim)\n",
    "decoder_outputs=decoder_embedding(decoder_inputs)\n",
    "\n",
    "#return_sequences=True, 모든 time step출력값 리턴\n",
    "decoder_lstm=LSTM(lstm_hidden_dim,\n",
    "    dropout=0.1,\n",
    "    return_state=True,\n",
    "    return_sequences=True)\n",
    "\n",
    "decoder_outputs, _, _=decoder_lstm(decoder_outputs, initial_state=encoder_states)\n",
    "\n",
    "#단어의 개수만큼 노드의 개수를 설정. 원핫 형식으로 각 단어 인덱스\n",
    "decoder_dense=Dense(len(words), activation='softmax')\n",
    "decoder_outputs=decoder_dense(decoder_outputs)\n",
    "\n",
    "#훈련 모델 정의\n",
    "\n",
    "model=models.Model([encoder_inputs,decoder_inputs],decoder_outputs)\n",
    "\n",
    "#학습 방법 설정\n",
    "model.compile(optimizer='rmsprop',\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예측 모델 정의\n",
    "#훈련 모델의 인코더 상태를 사용하여 예측 모델 인코더 설정\n",
    "encoder_model=models.Model(encoder_inputs,encoder_states)\n",
    "\n",
    "#예측 모델 디코더 정의\n",
    "#예측할때는 훈련할때와는 달리 타임 스텝을 한 단계씩 수행\n",
    "#매번 이전 디코더의 상태를 입력으로 받아서 새로 설정\n",
    "\n",
    "decoder_state_input_h=Input(shape=(lstm_hidden_dim,))\n",
    "decoder_state_input_c=Input(shape=(lstm_hidden_dim,))\n",
    "decoder_state_inputs=[decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "#임베딩 계층\n",
    "decoder_outputs=decoder_embedding(decoder_inputs)\n",
    "\n",
    "#lstm 계층\n",
    "decoder_outputs, state_h, state_c=decoder_lstm(decoder_outputs, initial_state=decoder_state_inputs)\n",
    "\n",
    "#히든 상태와 셀 상태를 하나로 묶음\n",
    "decoder_states=[state_h, state_c]\n",
    "\n",
    "#dense를 사용하여 원핫형식으로 인덱스 표현\n",
    "decoder_outputs=decoder_dense(decoder_outputs)\n",
    "\n",
    "#예측 모델 디코더 설정\n",
    "decoder_model=models.Model([decoder_inputs]+decoder_state_inputs,\n",
    "            [decoder_outputs]+decoder_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#훈련 및 테스트\n",
    "\n",
    "#인덱스를 문장으로 변환\n",
    "def convert_index_to_text(indexs, vocabulary):\n",
    "    sentence=\"\"\n",
    "    #print(index)   \n",
    "    for index in indexs:\n",
    "        if index==END_INDEX: #종료 인덱스 -> 중단\n",
    "            break;\n",
    "        if vocabulary.get(index) is not None:\n",
    "            sentence+=vocabulary[index]\n",
    "        else:\n",
    "            sentence.extend([vocabulary[OOV_INDEX]])\n",
    "        sentence += \" \"\n",
    "    #문장으로 변환\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total epoch: 1\n",
      "accuracy: 0.9836666655540466\n",
      "cost: 0.05115092784166336\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 2\n",
      "accuracy: 0.9896666502952576\n",
      "cost: 0.03157642111182213\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 3\n",
      "accuracy: 0.9936666774749756\n",
      "cost: 0.021514837816357612\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 4\n",
      "accuracy: 0.9953333473205567\n",
      "cost: 0.01886910654604435\n",
      "혼자 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 5\n",
      "accuracy: 0.9983333253860474\n",
      "cost: 0.00817704625427723\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 6\n",
      "accuracy: 0.9960000109672547\n",
      "cost: 0.011788732148706913\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 7\n",
      "accuracy: 1.0\n",
      "cost: 0.0019929814711213112\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 8\n",
      "accuracy: 0.9939999961853028\n",
      "cost: 0.018581857606768608\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 9\n",
      "accuracy: 0.9993333482742309\n",
      "cost: 0.002210194272920489\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 10\n",
      "accuracy: 1.0\n",
      "cost: 0.00024640391347929835\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 11\n",
      "accuracy: 1.0\n",
      "cost: 0.00015916594362352043\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 12\n",
      "accuracy: 1.0\n",
      "cost: 0.00020381265552714466\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 13\n",
      "accuracy: 0.999000015258789\n",
      "cost: 0.006086644260212779\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 14\n",
      "accuracy: 1.0\n",
      "cost: 0.00021562537469435483\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 15\n",
      "accuracy: 1.0\n",
      "cost: 5.10833015141543e-05\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 16\n",
      "accuracy: 1.0\n",
      "cost: 2.7249088816461153e-05\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 17\n",
      "accuracy: 1.0\n",
      "cost: 2.1652586146956308e-05\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 18\n",
      "accuracy: 1.0\n",
      "cost: 4.889418138191104e-05\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 19\n",
      "accuracy: 1.0\n",
      "cost: 7.316908668144606e-06\n",
      "여행 은 언제나 좋죠 \n",
      "\n",
      "total epoch: 20\n",
      "accuracy: 0.9996666717529297\n",
      "cost: 0.0006301542092114687\n",
      "여행 은 언제나 좋죠 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#model.fit()\n",
    "#x_encoder[2] => y+deocder[2]\n",
    "\n",
    "for epoch in range(20):\n",
    "    print(\"total epoch:\", epoch+1)\n",
    "    \n",
    "    history=model.fit([x_encoder,x_decoder],y_decoder,\n",
    "             epochs=100,\n",
    "             batch_size=64,\n",
    "             verbose=0)\n",
    "    print('accuracy:', history.history['acc'][-1])\n",
    "    print('cost:', history.history['loss'][-1])    \n",
    "    \n",
    "    #3박 4일 놀러 가고 싶다 ->여행 은 언제나 좋죠\n",
    "    input_encoder=x_encoder[2].reshape(1,x_encoder[2].shape[0])\n",
    "    input_decoder=x_decoder[2].reshape(1,x_decoder[2].shape[0])\n",
    "    results=model.predict([input_encoder,input_decoder])\n",
    "    \n",
    "    indexs=np.argmax(results[0], 1)\n",
    "    sentence=convert_index_to_text(indexs, index_to_word)\n",
    "    print(sentence)\n",
    "    print()  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input_encoder=x_encoder[2].reshape(1,x_encoder[2].shape[0])\n",
    "# input_decoder=x_decoder[2].reshape(1,x_decoder[2].shape[0])\n",
    "# results=model.predict([input_encode,input_decoder])\n",
    "\n",
    "#x_decoder[2].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\user\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(3, input_shape=(None, 1))`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.layers.recurrent.LSTM at 0x1c9699c8860>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSTM(3, input_dim=1, input_length=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x1c9699c8438>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dense(3, input_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예측을 위한 입력 생성\n",
    "def make_predict_input(sentence):\n",
    "    sentences=[]\n",
    "    sentences.append(sentence)\n",
    "    sentences=pos_tag(sentences)\n",
    "    input_seq=convert_text_to_index(sentences, word_to_index, ENCODER_INPUT)\n",
    "    return input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 생성\n",
    "def generate_text(input_seq):\n",
    "    #입력을 인코더에 넣어서 마지막 상태가 구해짐\n",
    "    states=encoder_model.predict(input_seq)\n",
    "    \n",
    "    #목표 시퀀스 초기화\n",
    "    target_seq=np.zeros((1,1))\n",
    "    \n",
    "    #목표 시퀀스의 첫번째 입력: <START>\n",
    "    target_seq[0,0]=STA_INDEX\n",
    "    \n",
    "    indexs=[]\n",
    "    while 1:\n",
    "        decoder_outputs, state_h, state_c=decoder_model.predict([target_seq]+states)\n",
    "        #결과가 원핫인코딩 형식인데 인덱스로 변환함\n",
    "        index=np.argmax(decoder_outputs[0,0,:])\n",
    "        indexs.append(index)\n",
    "        #종료조건 검사\n",
    "        if index==END_INDEX or len(indexs)>=max_sequences:\n",
    "            break\n",
    "        #목표 시퀀스를 바로 이전의 출력으로 설정\n",
    "        \n",
    "        \n",
    "        #목표 시퀀스 초기화\n",
    "        target_seq=np.zeros((1,1))\n",
    "        #목표 시퀀스의 첫번째 입력: <START>\n",
    "        target_seq[0,0]=index\n",
    "        \n",
    "        #디코더의 이전상태를 다음 디코더 예측에 사용\n",
    "        states=[state_h, state_c]\n",
    "    \n",
    "    #인덱스 집합이 문장으로 변환\n",
    "    sentence=convert_index_to_text(indexs, index_to_word)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[287, 324,   3, 104,  21, 302,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq=make_predict_input(\"집에 있을꺼야 3박 4일\")\n",
    "input_seq\n",
    "#[[300, 150, 170, ..., 0, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "곧 방학 이 예요 \n"
     ]
    }
   ],
   "source": [
    "sentence=generate_text(input_seq)\n",
    "print(sentence)\n",
    "#여행은 언제나 좋죠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
