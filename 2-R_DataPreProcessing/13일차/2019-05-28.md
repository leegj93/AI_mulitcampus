# 프로젝트 주제로 하면 좋을 것들

1. 영화 review 감정 분석
2. 신문 기사
3. 제품 review
4. 지식인

# 리뷰

## 1. list 관련 변수 다루기

```R
a <- list(1, 2, 3)
length(a)

class(seq(5, 10))
b <- as.list(seq(5, 10))
b

length(e) - 1
e[[5]]

e[[5]]

e[[length(e)-1]] <- 99
e

c <- as.list(seq(10, 14))
c[[1]] <- NULL # 특정 자료 삭제할 때는 NULL을 넣어주게 된다.

d[10:15]

# 여러개의 벡터를 좌우로 합치면(cbind, rbind) 행렬
a <- c(1,2,3)

matrix(1:6, ncol=3, byrow=TRUE)

cbind(c(1,2), c(3,4))
rbind(c(1,2), c(3,4))

# length: 벡터이든 행렬이든 상관없이 전체 원소 개수
a <- c(1,2,3)
length(a)
length(b)
#dim: 벡터의 경우에는 NULL, 행렬의 경우에는 크기벡터가 나옴
dim(a)
dim(b)

# 벡터 인덱싱: [[]], 서브세팅: []
a[1:2]
a[1]
a[[1]]

a <- rbind(1:4, 6:9)
a
# 8을 참조하여 출력
a[] # 전체
a[1, ] # 첫 번째 행
a[, 2] # 두 번째 열
a[2, 2:4] # 두 번째 행의 두번 째열부터 네번째 열까지
a[1:2, 2:3]

a <- 1:10
a
b <- a[-5]
b

vl < - c(T,F,T,T)
k <- 1:4
k[bl]
k[k%%2==0]

k <- k*10

# 변수 초기화
rep(NA, 10)

seq(0, 100, length=5)

set.seed(0)

rnorm(10) # 랜덤 값을 생성할 때 일반적으로 씀

# 가우시안 정규분포를 따르는 난수가 만들어진다.

runif(10) # 이 것도 랜덤 값을 생성할 때 사용되는데, 0~1까지 인자만큼의 구간을 나눠서 균등하게 출력해줌.

matrix(rnorm(10), c(2, 5))

x <- 1:10000
y <- 10001:20000
startTime <- proc.time()
# z <- rep(0, 10000)
for(i in 1:10000){
  z[i] <- x[i]+y[i]
}
endTime <- proc.time()
endTime - startTime

a <- c(1,2,3)
b <- c(4,2,1)
all(a == b)
any(a == b)
```



필요하지 않은 서비스는 쓸모가 없다.

실제 만들어졌을 때 contribution이 있어야 합니다.

재밌을 것 같아서 라는 이유는 쓸모가 없습니다.

# 감성분석

```R

exp(1)
log(a)
log10(a)

x <- 1:5
y <- rep(1, length(x))
x+y
x+2 # ( 2같은 경우 스칼라에서 확장이 되는데, 이 것을 브로드 캐스팅이라고 함)

x <- 50:59
which.max(x) # 최댓값의 index를 구함

x <- matrix(c(10, 20, 10, 20), nrow=2)
sum(x[,1])
colSums(x)

set.seed(123)
df <- data.frame(k1=c("x", "x", "y", "y", "x"),
                 k2=c("f", "s", "f", "s", "f"),
                 d1=rnorm(5),
                 d2=rnorm(5))
df
library(dplyr)
group_by(df, k1)

summarise(group_by(df, k1), myMean=mean(d1)) # k1이라는 키로 그룹화

summarise(group_by(df, k1, k2), myMean=mean(d1)) # k1, k2라는 키로 그룹화

library(tidyr) # r에서 데이터들을 깔끔하게 정리할 때.

# spread 함수는 pivot 테이블 형태로 변경할 수 있게 해주는 함수

spread(summarise(group_by(df, k1, k2), myMean=mean(d1)), k1, myMean)
# 피벗 테이블이 생성됨.
# R에서 연습을 많이 하지말고, 

# 두 데이터 프레임 합성

# 두 데이터프레임 합성 => join, merge
# bind: 단순 연결
# merge: 두 df의 공통 key를 사용하여 병합
df1 <- data.frame(k=c('b','b','a','c','a','a','b'),
                  d1=0:6)
df2 <- data.frame(k=c('a','b','d'),
                  d2=0:2)
df1
df2
merge(df1, df2, all=T) # all = T 모든 값이 NA더라도 다 나옵니다.
merge(df1, df2, all.x=T) # all.x = T 이면 첫 번째 인자가 NA인 것은 안 나옵니다.
# all.y 옵션도 있음

# afin study 검색해 보기
# bing이라고 해서 Bing Liu => 감성분석기 만든 사람.
# emolex => emotion lexicon, emolex는 화가 많이 났다든지 노여워한다든지, 

install.packages("tidytext") # 텍스트에 대한 감성 사전을 다운로드 합니다.
library(tidytext)
AFINN <- data.frame(get_sentiments("afinn"))
summary(AFINN)
table(AFINN$score)
which(AFINN$score == 0)
AFINN$word[2073]
table(tidytext$score)

hist(AFINN$score,
     xlim=c(-6, 6),
     col='blue',
     breaks = 20) # breaks는 중간중간에 공간

get_sentiments("bing")
get_sentiments("nrc")

table(AFINN$score)

oplex <- data.frame(get_sentiments("bing"))
table(oplex$sentiment) # negative/positive만 알려줌

emolex <- data.frame(get_sentiments("nrc"))
table(emolex$sentiment) # 다양한 감정들을 알려줌

emolex$word[emolex$sentiment == "anger"]

# 감성분석 => 긍정 / 부정

library(tm)
library(stringr)
library(dplyr)


my.text.location <- "papers/"
mypaper <- VCorpus(DirSource(my.text.location))
inpect(mypaper)

mypaper[[1]]
str(mypaper[[1]])
mypaper[[1]]$content
class(mypaper[[1]]$content)
unlist(mypaper[[1]][1]) # 벡터이긴한데, 약간 차이가 있음
as.character(mypaper[[1]][1]) # mypaper[[1]]$content

length(as.character(mypaper[[1]][1]))
length(unlist(mypaper[[1]][1]))

# inner join은 내부 조인이라 그러고,
# outer join은 외부 조인이라고 부릅니다.

#creating dataframe1
pd=data.frame(Name=c("Senthil","Senthil","Sam","Sam"),
              Month=c("Jan","Feb","Jan","Feb"),
              BS = c(141.2,139.3,135.2,160.1),
              BP = c(90,78,80,81))
print(pd)
#creating dataframe2
pd_new <- data.frame(Name=c("Senthil","Ramesh","Sam"),Department=c("PSE","Data Analytics","PSE"))
print(pd_new) 

left_join(pd, pd_new)
right_join(pd, pd_new)
inner_join(pd, pd_new)


mytxt <- rep(NA, 24)

for(i in 1:24){
  mytxt[i] <- as.character(mypaper[[i]][1])
}

data_frame(paper.id=1:24, doc=mytxt) # deprecated
my.df.text <- tibble(paper.id=1:24, doc=mytxt)

my.df.text.word <- my.df.text %>% 
  unnest_tokens(word, doc) # 단어가 분리가 됨.
# unnest_tokens: 문서 단위의 텍스트를 단어 단위의 텍스트로 변환
my.df.text.word

myresult.sa <- my.df.text.word %>% 
  inner_join(get_sentiments("bing")) %>% 
  count(word, paper.id, sentiment) %>% 
  spread(sentiment, n, fill=0)  # fill=0을 하면 NA 대신 0으로 채워집니다.
  
myagg <- summarise(group_by(myresult.sa, paper.id),
                   pos.sum=sum(positive),
                   neg.sum=sum(negative),
                   pos.sent=pos.sum-neg.sum)
myagg

myfilenames <- list.files(path=my.text.location,
                          all.files = TRUE)
paper.name <- myfilenames[3:26]
pub.year <- as.numeric(unlist(str_extract_all(paper.name, "[[:digit:]]{4}")))
paper.id <- 1:24
pub.year.df <- data.frame(paper.id, paper.name, pub.year)
pub.year.df

myagg %>% 
  left_join(pub.year.df) # 이게 결과임.

# 더 해서, 시각화를 할 수 있음

# 논문의 번호로 그룹바이 하고
# 각각의 그룹에 대해서 positive의 합, negative의 합을 구해보는 겁니다.

table(inner_join(my.df.text.word, BING)$sentiment)

# 코퍼스를 벡터로 만들었고, 벡터로 바꾸고 
my.df.text.word <- my.df.text

# data_frame: tidytext 형태로 데이터를 구성`
```



