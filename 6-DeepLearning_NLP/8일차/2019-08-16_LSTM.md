```python
model = Sequential()
model.add(Dense(4, input_dim=10, init='normal', activation='linear'))
model.add(Dense(1, activation='sigmoid'))
model.summary() # 요약정보
model.compile() # 
```

FFNN은 Feed Forward Neural Net이라는 의미인데,

RNN은 뒤로 가는 것이 있으므로 FFNN이 아니죠.

RNN에서 time-step이라는 말과 length라는 말은 혼용해서 같이 씁니다. 또한, sequence, sequence length도 같은 말입니다.

p. 케라스 책 보면, 264부터 RNN에 대한 이야기가 나와 있습니다.



```python
# tensorflow에서 rnn의 기본 구조
cell = tf.contrib.rnn.BasicRNNCell(num_units=hidden_size)
# cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_size)
outputs, _states = tf.nn.dynamic_rnn(cell, x_data, dtype=tf.float32)
```



# LSTM

- CBOW(continuous BOW)

# LSTM 설명 잘 되어 있는 곳

 http://colah.github.io/posts/2015-08-Understanding-LSTMs/ 