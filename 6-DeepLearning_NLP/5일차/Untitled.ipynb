{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianFilter:\n",
    "    def __init__(self):\n",
    "        self.words = set()\n",
    "        \n",
    "    \n",
    "    def fit(self):\n",
    "        pass\n",
    "    \n",
    "    def predict(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = BayesianFilter()\n",
    "bs.fit(\"파격 세일 - 오늘까지만 50% 할인\", \"광고\")\n",
    "bs.fit(\"무료 쿠폰 선물 & 무료 배송\", \"광고\")\n",
    "bs.fit(\"아사히 맥주 세일\", \"광고\")\n",
    "bs.fit(\"회의 일정 확인 부탁드립니다\", \"중요\")\n",
    "bs.fit(\"오늘 일정이 없습니다\", \"중요\")\n",
    "res, scorelist = bs.predict(\"재고 정리 할인, 무료 배송\")\n",
    "print(\"결과: \" % res) # 중요 or 광고\n",
    "print(scorelist) # 중요메일 / 광고메일 베이지안 필터기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4,5,6,7,8,9])\n",
    "y = np.array([12,23,34,45,56,77,88,100,90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 16:04:47.207478 10448 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0812 16:04:47.217425 10448 deprecation_wrapper.py:119] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 434.0409 - mean_squared_error: 434.0409\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 94.8119 - mean_squared_error: 94.8119\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 772us/step - loss: 94.2243 - mean_squared_error: 94.2243\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 93.7217 - mean_squared_error: 93.7217\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 93.2969 - mean_squared_error: 93.2969\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 92.9435 - mean_squared_error: 92.9435  \n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: 92.6553 - mean_squared_error: 92.6553\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 92.4266 - mean_squared_error: 92.4266\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: 92.2525 - mean_squared_error: 92.2525\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 92.1280 - mean_squared_error: 92.1280\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 92.0486 - mean_squared_error: 92.0486\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 92.0102 - mean_squared_error: 92.0102\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 92.0088 - mean_squared_error: 92.0088\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 92.0411 - mean_squared_error: 92.0411\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 92.1038 - mean_squared_error: 92.1038\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 92.1937 - mean_squared_error: 92.1937\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 92.3079 - mean_squared_error: 92.3079\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 92.4442 - mean_squared_error: 92.4442\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: 92.6000 - mean_squared_error: 92.6000\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 92.7730 - mean_squared_error: 92.7730\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 92.9614 - mean_squared_error: 92.9614\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 666us/step - loss: 93.1632 - mean_squared_error: 93.1632\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 93.3767 - mean_squared_error: 93.3767\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 93.6004 - mean_squared_error: 93.6004\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 93.8327 - mean_squared_error: 93.8327\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 94.0724 - mean_squared_error: 94.0724\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 94.3182 - mean_squared_error: 94.3182\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 94.5691 - mean_squared_error: 94.5691\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 94.8240 - mean_squared_error: 94.8240\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 95.0820 - mean_squared_error: 95.0820\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 95.3423 - mean_squared_error: 95.3423\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 95.6040 - mean_squared_error: 95.6040\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 95.8665 - mean_squared_error: 95.8665\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 96.1291 - mean_squared_error: 96.1291\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 96.3913 - mean_squared_error: 96.3913\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 96.6525 - mean_squared_error: 96.6525\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 96.9124 - mean_squared_error: 96.9124\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 97.1703 - mean_squared_error: 97.1703\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 97.4261 - mean_squared_error: 97.4261\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 97.6794 - mean_squared_error: 97.6794\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 97.9297 - mean_squared_error: 97.9297\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 664us/step - loss: 98.1770 - mean_squared_error: 98.1770\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 98.4210 - mean_squared_error: 98.4210\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 98.6614 - mean_squared_error: 98.6614\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 98.8980 - mean_squared_error: 98.8980\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 99.1309 - mean_squared_error: 99.1309\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 99.3598 - mean_squared_error: 99.3598\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 99.5845 - mean_squared_error: 99.5845\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 99.8050 - mean_squared_error: 99.8050\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 100.0213 - mean_squared_error: 100.0213\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 100.2333 - mean_squared_error: 100.2333\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 100.4409 - mean_squared_error: 100.4409\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 100.6442 - mean_squared_error: 100.6442\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 100.8430 - mean_squared_error: 100.8430\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 101.0375 - mean_squared_error: 101.0375\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 101.2276 - mean_squared_error: 101.2276\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 101.4133 - mean_squared_error: 101.4133\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 101.5946 - mean_squared_error: 101.5946\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 101.7716 - mean_squared_error: 101.7716\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 101.9444 - mean_squared_error: 101.9444\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 102.1128 - mean_squared_error: 102.1128\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 102.2771 - mean_squared_error: 102.2771\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 102.4372 - mean_squared_error: 102.4372\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 102.5933 - mean_squared_error: 102.5933\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 102.7452 - mean_squared_error: 102.7452\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 102.8932 - mean_squared_error: 102.8932\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 103.0374 - mean_squared_error: 103.0374\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 103.1776 - mean_squared_error: 103.1776\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 103.3141 - mean_squared_error: 103.3141\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 103.4469 - mean_squared_error: 103.4469\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 666us/step - loss: 103.5760 - mean_squared_error: 103.5760\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 103.7016 - mean_squared_error: 103.7016\n",
      "Epoch 73/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 554us/step - loss: 103.8236 - mean_squared_error: 103.8236\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 103.9423 - mean_squared_error: 103.9423\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 104.0576 - mean_squared_error: 104.0576\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 104.1696 - mean_squared_error: 104.1696\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 104.2785 - mean_squared_error: 104.2785\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 104.3842 - mean_squared_error: 104.3842\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 104.4868 - mean_squared_error: 104.4868\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 104.5865 - mean_squared_error: 104.5865\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 104.6834 - mean_squared_error: 104.6834\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 104.7773 - mean_squared_error: 104.7773\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 104.8684 - mean_squared_error: 104.8684\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 104.9570 - mean_squared_error: 104.9570\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 105.0429 - mean_squared_error: 105.0429\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 105.1261 - mean_squared_error: 105.1261\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 105.2070 - mean_squared_error: 105.2070\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 105.2853 - mean_squared_error: 105.2853\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 105.3613 - mean_squared_error: 105.3613\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 105.4351 - mean_squared_error: 105.4351\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 105.5066 - mean_squared_error: 105.5066\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 105.5759 - mean_squared_error: 105.5759\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 105.6431 - mean_squared_error: 105.6431\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 105.7083 - mean_squared_error: 105.7083\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 105.7714 - mean_squared_error: 105.7714\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 105.8326 - mean_squared_error: 105.8326\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 105.8919 - mean_squared_error: 105.8919\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 105.9495 - mean_squared_error: 105.9495\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.0051 - mean_squared_error: 106.0051\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 106.0591 - mean_squared_error: 106.0591\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 106.1114 - mean_squared_error: 106.1114\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 664us/step - loss: 106.1620 - mean_squared_error: 106.1620\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 774us/step - loss: 106.2112 - mean_squared_error: 106.2112\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: 106.2587 - mean_squared_error: 106.2587\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 91.6909 - mean_squared_error: 91.69 - 0s 888us/step - loss: 106.3048 - mean_squared_error: 106.3048\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 106.3494 - mean_squared_error: 106.3494\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 106.3926 - mean_squared_error: 106.3926\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 106.4344 - mean_squared_error: 106.4344\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.4750 - mean_squared_error: 106.4750\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.5142 - mean_squared_error: 106.5142\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.5522 - mean_squared_error: 106.5522\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 106.5890 - mean_squared_error: 106.5890\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 106.6246 - mean_squared_error: 106.6246\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 106.6592 - mean_squared_error: 106.6592\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 106.6926 - mean_squared_error: 106.6926\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 106.7249 - mean_squared_error: 106.7249\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.7562 - mean_squared_error: 106.7562\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 106.7865 - mean_squared_error: 106.7865\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 106.8158 - mean_squared_error: 106.8158\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.8443 - mean_squared_error: 106.8443\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 106.8717 - mean_squared_error: 106.8717\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 106.8983 - mean_squared_error: 106.8983\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 106.9241 - mean_squared_error: 106.9241\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.9490 - mean_squared_error: 106.9490\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 106.9731 - mean_squared_error: 106.9731\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 106.9965 - mean_squared_error: 106.9965\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.0191 - mean_squared_error: 107.0191\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.0409 - mean_squared_error: 107.0409\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: 107.0621 - mean_squared_error: 107.0621\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 554us/step - loss: 107.0826 - mean_squared_error: 107.0826\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.1025 - mean_squared_error: 107.1025\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.1216 - mean_squared_error: 107.1216\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.1401 - mean_squared_error: 107.1401\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.1581 - mean_squared_error: 107.1581\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.1755 - mean_squared_error: 107.1755\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 664us/step - loss: 107.1923 - mean_squared_error: 107.1923\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.2086 - mean_squared_error: 107.2086\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 107.2243 - mean_squared_error: 107.2243\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.2396 - mean_squared_error: 107.2396\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 107.2543 - mean_squared_error: 107.2543\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.2685 - mean_squared_error: 107.2685\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.2823 - mean_squared_error: 107.2823\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.2957 - mean_squared_error: 107.2957\n",
      "Epoch 144/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 776us/step - loss: 107.3086 - mean_squared_error: 107.3086\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.3211 - mean_squared_error: 107.3211\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.3332 - mean_squared_error: 107.3332\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.3449 - mean_squared_error: 107.3449\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.3561 - mean_squared_error: 107.3561\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.3672 - mean_squared_error: 107.3672\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.3778 - mean_squared_error: 107.3778\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.3880 - mean_squared_error: 107.3880\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.3978 - mean_squared_error: 107.3978\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.4074 - mean_squared_error: 107.4074\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.4167 - mean_squared_error: 107.4167\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.4256 - mean_squared_error: 107.4256\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.4344 - mean_squared_error: 107.4344\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.4427 - mean_squared_error: 107.4427\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.4508 - mean_squared_error: 107.4508\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.4587 - mean_squared_error: 107.4587\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.4663 - mean_squared_error: 107.4663\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.4736 - mean_squared_error: 107.4736\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.4807 - mean_squared_error: 107.4807\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.4876 - mean_squared_error: 107.4876\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.4943 - mean_squared_error: 107.4943\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.5007 - mean_squared_error: 107.5007\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.5069 - mean_squared_error: 107.5069\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.5129 - mean_squared_error: 107.5129\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.5188 - mean_squared_error: 107.5188\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.5244 - mean_squared_error: 107.5244\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.5299 - mean_squared_error: 107.5299\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.5351 - mean_squared_error: 107.5351\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 554us/step - loss: 107.5403 - mean_squared_error: 107.5403\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.5452 - mean_squared_error: 107.5452\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.5499 - mean_squared_error: 107.5499\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.5545 - mean_squared_error: 107.5545\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.5589 - mean_squared_error: 107.5589\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.5633 - mean_squared_error: 107.5633\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.5675 - mean_squared_error: 107.5675\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.5714 - mean_squared_error: 107.5714\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.5754 - mean_squared_error: 107.5754\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 774us/step - loss: 107.5791 - mean_squared_error: 107.5791\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.5828 - mean_squared_error: 107.5828\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.5863 - mean_squared_error: 107.5863\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.5897 - mean_squared_error: 107.5897\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.5930 - mean_squared_error: 107.5930\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.5963 - mean_squared_error: 107.5963\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.5993 - mean_squared_error: 107.5993\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6024 - mean_squared_error: 107.6024\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6052 - mean_squared_error: 107.6052\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6080 - mean_squared_error: 107.6080\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6107 - mean_squared_error: 107.6107\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6133 - mean_squared_error: 107.6133\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6159 - mean_squared_error: 107.6159\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6183 - mean_squared_error: 107.6183\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.6207 - mean_squared_error: 107.6207\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6229 - mean_squared_error: 107.6229\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: 107.6251 - mean_squared_error: 107.6251\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6273 - mean_squared_error: 107.6273\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.6294 - mean_squared_error: 107.6294\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6313 - mean_squared_error: 107.6313\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6333 - mean_squared_error: 107.6333\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: 107.6352 - mean_squared_error: 107.6352\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6369 - mean_squared_error: 107.6369\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6387 - mean_squared_error: 107.6387\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6404 - mean_squared_error: 107.6404\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6421 - mean_squared_error: 107.6421\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6436 - mean_squared_error: 107.6436\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6452 - mean_squared_error: 107.6452\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6467 - mean_squared_error: 107.6467\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.6481 - mean_squared_error: 107.6481\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6494 - mean_squared_error: 107.6494\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6508 - mean_squared_error: 107.6508\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 555us/step - loss: 107.6521 - mean_squared_error: 107.6521\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6533 - mean_squared_error: 107.6533\n",
      "Epoch 215/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 556us/step - loss: 107.6546 - mean_squared_error: 107.6546\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6558 - mean_squared_error: 107.6558\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6569 - mean_squared_error: 107.6569\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6579 - mean_squared_error: 107.6579\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6590 - mean_squared_error: 107.6590\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.6600 - mean_squared_error: 107.6600\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6610 - mean_squared_error: 107.6610\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6620 - mean_squared_error: 107.6620\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6629 - mean_squared_error: 107.6629\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6638 - mean_squared_error: 107.6638\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6647 - mean_squared_error: 107.6647\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6655 - mean_squared_error: 107.6655\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6664 - mean_squared_error: 107.6664\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6671 - mean_squared_error: 107.6671\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6678 - mean_squared_error: 107.6678\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6686 - mean_squared_error: 107.6686\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6693 - mean_squared_error: 107.6693\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6700 - mean_squared_error: 107.6700\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6707 - mean_squared_error: 107.6707\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6713 - mean_squared_error: 107.6713\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6719 - mean_squared_error: 107.6719\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6726 - mean_squared_error: 107.6726\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6731 - mean_squared_error: 107.6731\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 107.6736 - mean_squared_error: 107.6736\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6742 - mean_squared_error: 107.6742\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6747 - mean_squared_error: 107.6747\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6752 - mean_squared_error: 107.6752\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6757 - mean_squared_error: 107.6757\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.6762 - mean_squared_error: 107.6762\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6766 - mean_squared_error: 107.6766\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6771 - mean_squared_error: 107.6771\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6776 - mean_squared_error: 107.6776\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6779 - mean_squared_error: 107.6779\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 554us/step - loss: 107.6784 - mean_squared_error: 107.6784\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6788 - mean_squared_error: 107.6788\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6792 - mean_squared_error: 107.6792\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6795 - mean_squared_error: 107.6795\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.6799 - mean_squared_error: 107.6799\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6802 - mean_squared_error: 107.6802\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.6805 - mean_squared_error: 107.6805\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6808 - mean_squared_error: 107.6808\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: 107.6811 - mean_squared_error: 107.6811\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6814 - mean_squared_error: 107.6814\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6817 - mean_squared_error: 107.6817\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 664us/step - loss: 107.6820 - mean_squared_error: 107.6820\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6822 - mean_squared_error: 107.6822\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6825 - mean_squared_error: 107.6825\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 107.6828 - mean_squared_error: 107.6828\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.6830 - mean_squared_error: 107.6830\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6832 - mean_squared_error: 107.6832\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6835 - mean_squared_error: 107.6835\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.6837 - mean_squared_error: 107.6837\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6839 - mean_squared_error: 107.6839\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6841 - mean_squared_error: 107.6841\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6843 - mean_squared_error: 107.6843\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6845 - mean_squared_error: 107.6845\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6847 - mean_squared_error: 107.6847\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: 107.6849 - mean_squared_error: 107.6849\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6851 - mean_squared_error: 107.6851\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6852 - mean_squared_error: 107.6852\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 666us/step - loss: 107.6854 - mean_squared_error: 107.6854\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6855 - mean_squared_error: 107.6855\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 553us/step - loss: 107.6856 - mean_squared_error: 107.6856\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6858 - mean_squared_error: 107.6858\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: 107.6860 - mean_squared_error: 107.6860\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6861 - mean_squared_error: 107.6861\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6862 - mean_squared_error: 107.6862\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 554us/step - loss: 107.6864 - mean_squared_error: 107.6864\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6865 - mean_squared_error: 107.6865\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6866 - mean_squared_error: 107.6866\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6867 - mean_squared_error: 107.6867\n",
      "Epoch 286/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 776us/step - loss: 107.6868 - mean_squared_error: 107.6868\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6869 - mean_squared_error: 107.6869\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6870 - mean_squared_error: 107.6870\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: 107.6871 - mean_squared_error: 107.6871\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6872 - mean_squared_error: 107.6872\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 107.6874 - mean_squared_error: 107.6874\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: 107.6875 - mean_squared_error: 107.6875\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6875 - mean_squared_error: 107.6875\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6876 - mean_squared_error: 107.6876\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6877 - mean_squared_error: 107.6877\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6878 - mean_squared_error: 107.6878\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: 107.6879 - mean_squared_error: 107.6879\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: 107.6879 - mean_squared_error: 107.6879\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6879 - mean_squared_error: 107.6879\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: 107.6881 - mean_squared_error: 107.6881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29f08acc550>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=1, activation='linear'))\n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
    "model.fit(x, y, batch_size=1, epochs=300, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66.25939]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([7.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29f0a3bbc88>,\n",
       " <matplotlib.lines.Line2D at 0x29f0a3bbe80>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x, model.predict(x), 'b', x, y, 'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0812 16:26:22.320245 10448 deprecation.py:323] From C:\\Users\\user\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 0s 32ms/step - loss: -661.9172 - binary_accuracy: 0.0000e+00\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 773us/step - loss: -889.7827 - binary_accuracy: 0.0000e+00\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: -894.3633 - binary_accuracy: 0.0000e+00\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: -898.8274 - binary_accuracy: 0.0000e+00\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -903.5796 - binary_accuracy: 0.0000e+00\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -906.3494 - binary_accuracy: 0.0000e+00\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -906.6187 - binary_accuracy: 0.0000e+00\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -906.8879 - binary_accuracy: 0.0000e+00\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -907.1562 - binary_accuracy: 0.0000e+00\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: -907.4267 - binary_accuracy: 0.0000e+00\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -907.6967 - binary_accuracy: 0.0000e+00\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 967us/step - loss: -907.9643 - binary_accuracy: 0.0000e+00\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -908.2307 - binary_accuracy: 0.0000e+00\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: -908.5034 - binary_accuracy: 0.0000e+00\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: -908.7695 - binary_accuracy: 0.0000e+00\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: -909.0464 - binary_accuracy: 0.0000e+00\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -909.2986 - binary_accuracy: 0.0000e+00\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -909.5841 - binary_accuracy: 0.0000e+00\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -909.8330 - binary_accuracy: 0.0000e+00\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -910.0959 - binary_accuracy: 0.0000e+00\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -910.3686 - binary_accuracy: 0.0000e+00\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -910.6413 - binary_accuracy: 0.0000e+00\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -910.8951 - binary_accuracy: 0.0000e+00\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -911.2158 - binary_accuracy: 0.0000e+00\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -911.4885 - binary_accuracy: 0.0000e+00\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -911.6517 - binary_accuracy: 0.0000e+00\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -912.0630 - binary_accuracy: 0.0000e+00\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -912.3357 - binary_accuracy: 0.0000e+00\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -912.6873 - binary_accuracy: 0.0000e+00\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -912.6873 - binary_accuracy: 0.0000e+00\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -913.1829 - binary_accuracy: 0.0000e+00\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -913.1829 - binary_accuracy: 0.0000e+00\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 996us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 774us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 666us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 73/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 774us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - ETA: 0s - loss: -175.3662 - binary_accuracy: 0.0000e+ - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 144/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 902us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 846us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 774us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 888us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 215/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 777us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 775us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 998us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 885us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - ETA: 0s - loss: -175.3662 - binary_accuracy: 0.0000e+ - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 285/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 886us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 664us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 776us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 665us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 887us/step - loss: -914.0300 - binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29f0a40d7f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 로지스틱 회기\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=1, activation='sigmoid'))\n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "model.fit(x, y, batch_size=1, epochs=300, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29f0aab9da0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(x, model.predict(x), 'b', x, y, 'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([15, 17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([100, 90, 80], [55,45,36], [77, 88, 90]) # 중간, 기말, 최종\n",
    "y = np.array([92, 70, 88])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=1, activation='linear'))\n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
    "model.fit(x, y, batch_size=1, epochs=300, shuffle=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
