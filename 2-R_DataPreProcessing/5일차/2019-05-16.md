```R
rbind(c(1,2,3), c(4,5,6))
id=c(1,2), name=c("a","b"), stringAsFactors = F)	# 모든 문자열이 Factor로 읽어짐

cbind(c(1,2,3),c(4,5,6))
```

sapply, mapply, lapply(주로 사용되는 apply 함수)

데이터 타입이, scalar, vector, vector들이 연결이 되어지면, 2차원 구조로 연결되면 행렬이 됩니다.

저장되어있는 데이터의 타입이 모두 같습니다.

그 다음으로 이제, list라고 하는 자료 구조는 데이터 타입이 모두 달라도 상관이 없어요.

list 안에 저장되어 있는 자료들은요, list안에 vector도 저장할 수도 있고, dataframe을 저장할 수도 있고 다양한 자료들을 모조리 저장할 수 있습니다.

lapply는 결과값이 list로 나옴

sapply는 vector, 행렬로 return 되는 것이 saplly

tapply가 또 많이쓰입니다.

tapply는 자료를 처리하기 위해서 기준을 주고 그룹핑을 하고 특정함수를 apply하는거죠.

tapply에서는 1차적으로 그루핑을 한다. 각각의 그룹에 대해서 함수를 적용한다.

tapply라는 함수가 있다.

외에 mapply라는 함수는 쓰임은 거의 없는 편입니다. multiple list, multiple vector를 인수로 받아서 처리를 한다.

이러한 계열의 apply함수가 있습니다.

행에 대한 합계를 구하고 싶을 때. sum함수가 있잖아요. sum함수를 적용하면 되는데

이럴 때 일괄적으로 적용하고자 할 때 유용한 함수가 apply입니다.
```R
a<-matrix(1:9, ncol=3)
a
apply(a, 1, sum)  # 1 => 행 단위로 덧셈이 됨.
apply(a, 2, sum)  # 2 => 열 단위로 덧셈이 됨.
# ~ 자료에 ~ 함수를 적용해라.

# iris data의 첫번째 열부터 4번째 열까지 각각의 합을 구하라.
apply(iris[,1:4], 2, sum)

rowSums(iris[,1:4])
colSums(iris[,1:4])

res<-lapply(1:3, function(x){x*2})
res

res[[3]]

class(res)
res<-unlist(res)
res
class(res)
x<-list(a=1:3, b=4:6)
x

lapply(iris[,1:4], mean)        # list
sapply(iris[,1:4], mean)        # vector
```


```R
sapply(iris[, 1:4], function(x){x>3})
rep(1,10)           # 1을 10번 반복시켜주는 함수
tapply(1:10, rep(1, 10), sum)
# tapply(vector, group index, 그룹단위 적용 함수)
tapply(1:10, 1:10%%2==1, sum)       # 1은 TRUE그룹, 2는 FALSE그룹, 3은 TRUE 그룹. 따라서 tapply는 그룹별로 적용됩니다.
tapply(iris$Sepal.Length, iris$Species,mean)  # 종별로 mean을 구하고 싶은 경우
```

### doBy패키지: 데이터를 그룹단위 처리

약간 예전 패키지인데, 알면 도움이 됩니다.

```R
summary(iris)
```
quantile은 5개의 수를 보여주는 것이라서 five수라고도 합니다. 

```R
quantile(iris$Sepal.Length)
quantile(iris$Sepal.Length), seq(0, 1, by=0.1)))    # 5분위 수가 아니라, 이렇게하면 10분위 수로 만들어 줍니다.
summaryBy( ~ 기준)

# tild 오른쪽이 기준이 되는 것입니다. 어떤 기준으로 요약할 것인가 하는 것을 지정하여 요약하는 함수입니다.

summaryBy(Sepal.Length~Species, iris)

summaryBy(Sepal.Length+Sepal.Width~Species, iris)

order(iris$Sepal.Length)        # 정렬을 하는데, 정렬 결과가 index로 나옵니다.

iris[order(iris$Sepal.Length, iris$Sepal.Width)]      # 첫 번째 기준, 두 번째 기준
# orderBy도 order랑 거의 비슷한데, 수식을 줄 수 있다는 점이 특이합니다.

orderBy(~Sepal.Width+Sepal.Length, iris)        # ~ 뒷 부분이 기준이고, 2차기준은 +기호로 추가합니다.

sample(1:45, 6) # 비복원추출. 한 번 뽑히면 더 이상 뽑히지 않는 추출방법입니다.
sample(1:45, 6, replace=TRUE)       # 복원 추출
```

### 프로젝트 할 때 순서

1. 요구사항 분석
2. 계획 수립
3. data 수집(db, web, ...)
4. data 전처리(na, 상관관계, 차원축소(pca, lda, t-sn), 특징 선택, ...)
5. data 분석(dplyr, ..., numpy, pandas, seaborn, matplotlib, ...) -> EDA(탐색적 분석 방법)
6. 모델링 알고리즘 선택(ML(kmeans, knn, dt, rf, /DL...)
7. 모델링
8. 모델(y=ax+b)
9. validation check(k-fold) => TP, TN, FP, FN 같은 confusion matrix가 나옵니다.
10. 성능 평가 -> 개선(이 부분이 계속 반복됩니다. data전처리 / 모델링 알고리즘 선택 / 모델링)
11. 척도: precision, recall, f-measure, support



```R
iris[sample(NROW(iris), NROW(iris)),]   # 150개 중에서 150개를 뽑아라. 즉, 1번부터 150번까지를 랜덤으로 추출하라.
# validation set만들 때 랜덤으로 섞어서 7:3 정도로 뽑거나 할 수 있음

sampleBy(~Species, frac=0.1, data=iris)    # frac은 몇 퍼센트만큼 뽑을 지. 총 150개의 데이터 중에서 15개만 뽑음. 딱 종 별로 5개씩 나옵니다.
# 종 별로 고르게 샘플링됩니다.

# 나중에 머신러닝할 때 이런 부분들을 다룰겁니다.

# 병합하는 과정에서 join말고도 merge도 있습니다. python에도 동일하게 있는데, 데이터를 분리하는 것은 split이 있습니다.
split(iris, iris$Species)       # 이렇게 하면 종 별로 나뉘어서 들어가는데, list로 데이터가 저장이 됩니다.
class(split(iris, iris$Species))    # list type
subset(iris, Species=="setosa")     # 종이 setosa인 것만 추출

subset(iris, Species=="setosa" & Sepal.Length>5.0)  # 두가지 조건을 동시에 만족하는 것을 추출함
subset(iris, select=c(Species, Sepal.Length))       # select 인자를 줘서, 두 개의 컬럼만 선택할 수 있음.
subset(iris, select=-c(Species, Sepal.Length))       # select 인자를 줘서, 두 개의 컬럼만 제외하고 선택할 수 있음.

names(iris)     # 컬럼의 이름이 나오는 함수

iris[, names(iris) %in% c("Species", "Sepal.Length")]       # 특정한 컬럼 이름들만 선택하기
iris[, !names(iris) %in% c("Species", "Sepal.Length")]      # 특정한 컬럼 이름들만 제외하고 선택하기

# 두 열을 합칠 때는 cbind
x<-data.frame(name=c("a","b","c"),
              math=c(1,2,3))
y<-data.frame(name=c("c","b","a"),
              eng=c(1,2,3))
cbind(x, y)
# 이렇게 하면 단순연결을 해버립니다. 단순히 컬럼을 연결해주는 함수입니다.

merge(x, y)
# name 기준 병합

x<-data.frame(name=c("a","b","c"),
              math=c(1,2,3))
y<-data.frame(name=c("c","b","d"),      # y의 값 하나가 a->d로 바뀌었음.
              eng=c(1,2,3))
merge(x, y)     #이름이 같지 않은 것들은 나오지 않음.
merge(x, y,all=TRUE)    # 값을 가지고 있지 않은 것들은 NA가 나오게 됩니다.

x<-c(5,2,1,4,3)
sort(x)
sort(x, decreasing = TRUE)
x       # x의 순서는 실제로 바뀌지 않았습니다.

data=list()
n=10
for(c in 1:n){
    data=data.frame(Index=1, myChar=sample(letters, 1), z=runif(1))
}
letters

runif(1)        # 난수를 생성하주는 것

data=list()
n=10
for(c in 1:n){
  data[[c]]=data.frame(Index=c, myChar=sample(letters, 1), z=runif(1))      # list 쓸 때는 대괄호 2개를 중첩해서 사용합니다.
}

# 1. rbind
do.call(rbind, data)
#ldply(l: 함수로 입력되는 데이터 타입은 list. d: 출력되는 데이터 타입은 dataframe)
# 하지만 시간이 많이 걸림.

#2. ldply
install.packages("plyr")
library(plyr)
ldply(data, rbind)  # data, function

#3. rbindlist
install.packages("data.table")
library(data.table)
rbindlist(data)

# 결론적으로 rbindlist가 속도가 가장 빠릅니다.

# with는 field 이름만 가지고 접근할 수 있도록 해줍니다.

mean(iris$Sepal.Length)

with(iris,{
  mean(Sepal.Length)
})

# which문은 조건에 맞는 index를 return 해줌
which(iris$Species=="setosa")   
which.min(iris$Sepal.Length)    # 최소값이 있는 곳에 대한 index가 나옴
which.max(iris$Sepal.Length)    # 최소값이 있는 곳에 대한 index가 나옴


x<-c(5,5,6,6,6,7,7,5,7,7)
# 최빈수 출력
names(which.max(table(x)))  # 7이 가장 많고, index가 3이다.
```

R에서는 마지막 값을 포함하지 않습니다.

## MySQL

왼쪽에 스키마 단추를 누르면, 둥근 원통 모양의 아이콘이 있죠. 원통 기호는 통상정ㄱ으로 데이터베이슥 ㅣ호에요.

일단 여러분들이 데이터베이스를 만들 때, 이 쪽에서도

mysql에는 스키마라고 하면 데이터베이스를 말합니다. 하지만 oracle쪽으로 가면, 똑같은 의미가 아니에요.

환경변수를 설정하는 것은 커맨드 창에서

```cmd
setx path "%path%;c:\"
```

```sql
create database rprogramming;
use rprogramming;
create table rtest2(
	name varchar(20),
    score integer
);

insert into rtest2 values("a", 50);-- insert명령은 auto commit 기능이 있어서, 자동으로 업데이트 될 거에요.
insert into rtest2 values("b", 90);
commit;
-- 이렇게 하면 데이터베이스에 완벽하게 저장이 되었습니다.
select * from rtest2;
select * from rprogramming.rtest2;
```


```R

install.packages("RMySQL")
library(RMySQL)
con<-dbConnect(MySQL(), user="root", password="1234", host="127.0.0.1", dbname="rprogramming")
dbListTables(con)
dbGetQuery(con, "select * from rtest2")

```

R에서 위와 같이 입력하면 데이터베이스에서 데이터를 가져올 수 있습니다.


Ozone에 대해서 산점도(scatter plot) 그리기.
```R

install.packages("mlbench") # data가 많이 들어가 있습니다.
library(mlbench)
data(Ozone)
head(Ozone)
plot(Ozone$V8, Ozone$V9, xlab = "Temp1", ylab="Temp2", main="Ozone", pch=20)
plot(Ozone$V8, Ozone$V9, xlab = "Temp1", ylab="Temp2", main="Ozone", pch='*', cex=3)
# cex는 기본 크기의 3배 라는 의미. 0.1이면 기본 점의 크기의 10% 라는 의미입니다.
plot(Ozone$V8, Ozone$V9, xlab = "Temp1", ylab="Temp2", main="Ozone", pch=20, col="#f2723e", col.axis="#0000ff")
plot(Ozone$V8, Ozone$V9, xlab = "Temp1", ylab="Temp2", main="Ozone", pch=20, xlim=c(0, 100), ylim=c(0, 100))

min(Ozone$V8, na.rm=T)
min(Ozone$V9, na.rm=T)
max(Ozone$V8, na.rm=T)
max(Ozone$V9, na.rm=T)

# 위의 명령어를 이용해서 축의 위치를 결정하면 되겠네요.

help(par) # 자주 쓰이는 변수가 cex(점의 크기). col(색상), type도 있고 그렇죠?
# 시각화를 할 수 있는 옵션들입니다.
```

자동차에 대한 제동거리 산점도 그리기
```R
cars

plot(cars)
plot(cars, type="l")
plot(cars, type="b")
plot(cars, type="o")    # 점과 선이 중첩되어 연결되어 있음

tapply(cars$dist, cars$speed, mean)


# Q. speed로 그룹화 해서 dist에 대한 평균을 출력하는 프로그램을 만들어라.
ds<-tapply(cars$dist, cars$speed, mean)
plot(ds, xlab="speed", ylab="dist", type="o", cex=0.5)
plot(ds, xlab="speed", ylab="dist", type="o", cex=0.5, lty="dashed")  # lty는 line type의 줄임말.
```


### 그림 저장

그림 하나를 figure라고 합니다.

이 그래프를 창 하나에 그래프가 하나가 출력되는 것이 기본이긴 한데, 이 figure를 나누어서

여러개의 그래프를 시각화 해야 하는 경우가 많이 있어요

창 하나에 그래프가 하나 출력됐지만, 여러개 출력해야 하는 경우도 맣ㄴ다.

예를들어서 상반기 합나기, 계절별로 나누어서 한다든지, 월별로 한다든지. 시각화 해야 하는경우가 잇을 수 잇는데

창을 나누는 작업을 해준 다음에 시각화 해주는 것이 좋습니다.

parameter지정하는 함수가 par였잖아요. 그것을 이용해서 해보도록 하겠습니다.

```R
par()

myPar<-par(mfrow=c(2,1))  # 창을 나누는 방법
plot(Ozone$V8, Ozone$V9, main="Ozone")
plot(Ozone$V8, Ozone$V9, main="Ozone2")
par(myPar)  # myPar를 설정하기 때문에 plot 설정하기 이전의 설정으로 되돌립니다.
plot(Ozone$V8, Ozone$V9, main="Ozone2")
# 제거를 할 때는 plot의 빗자루 형태를 눌러보면 됩니다.
```

plot함수가 저장된 패키지가 graphics라는 패키지에 저장이 돼 있네요.

par를 봐라라고 되어있는데, graphics의 par함수도 양이 상당히 많습니다.

ggplot 사용법
```R

# ggplot 패키지 시각화
# 1단계: 배경(axes-axis 2개) 설정
# 2단계: 배경에 그래프 출력
# 3단계: 옵션 지정(축, 색상...)
library(ggplot2)
#1. 배경설정
ggplot(data=mpg, aes(x=displ, y=hwy))

#2. 배경에 그래프 출력
ggplot(data=mpg, aes(x=displ, y=hwy))+geom_point()

#3. 옵션 지정
ggplot(data=mpg, aes(x=displ, y=hwy))+geom_point()+xlim(0,10)+ylim(0,50)

# 보통 하나에 다 쓰는 경우는 잘 없고, +로 구분해서 여러줄로 쓰는 경우가 많습니다.
ggplot(data=mpg, aes(x=displ, y=hwy))+
geom_point()+
xlim(0,10)+
ylim(0,50)
```

ggplot은 상세하게 그래프를 그릴 때. ex, 공모전에 참가했을 때.

qplot은 간단하게 그래프를 그릴 때 사용합니다.

```R
library(dplyr)
df<-mpg %>% 
  group_by(drv) %>% 
  summarise(meanHwy=mean(hwy))
df
# tibble은 데이터프레임을 약간 개선한 것이라고 보면 됩니다.

ggplot(data=df, aes(x=drv, y=meanHwy))+geom_col() # 순서가 원하지 않는 순서로 되어있습니다.
ggplot(data=df, aes(x=reorder(drv, meanHwy), y=meanHwy))+geom_col() # meanHwy값을 기준으로 drv를 오름차순 정렬해라.
ggplot(data=df, aes(x=reorder(drv, -meanHwy), y=meanHwy))+geom_col() # meanHwy값을 기준으로 drv를 내림차순 정렬해라.
ggplot(data=mpg, aes(x=drv))+geom_bar()   # 빈도수 그래프는 x축만 지정하면 됩니다. drv는 주행거리
ggplot(data=mpg, aes(x=cty))+geom_bar()   # 빈도수 그래프는 x축만 지정하면 됩니다. cty는 도시에서의 주행거리.
# geom_col(): 평균 -> 그래프
# geom_bar(): 빈도 -> 그래프
```

finance.yahoo.com으로 접속해서

multicampus coorporation을 검색합니다.

historical data 탭으로 들어가서 기간은 5년으로 설정한 다음, apply 합니다.

volumne은 거래량이에요.

이와 같은 데이터 셋은요. 시각화를 한 다음에 분석할 필요가 있어요.

volumne은 다른 값들보다 굉장히 크죠. 천 단위여서, 표준화를 해줘야합니다.

다운로드 누르면 엑셀파일로 바로 다운로드 받을 수 있습니다.

```R
economics
ggplot(data=economics, aes(x=date, y=unemploy))+geom_line()
# 라인그래프로 그리면 뭔가 변화의 추이가 보이죠
```

